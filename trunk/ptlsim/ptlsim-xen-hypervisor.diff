diff -r ea04335d238b xen/arch/x86/dom0_ops.c
--- a/xen/arch/x86/dom0_ops.c	Thu Aug  3 18:45:14 2006
+++ b/xen/arch/x86/dom0_ops.c	Wed Aug 16 04:26:29 2006
@@ -47,6 +47,92 @@
 {
     if ( ((1 << smp_processor_id()) & msr_cpu_mask) )
         (void)rdmsr_safe(msr_addr, msr_lo, msr_hi);
+}
+
+/*
+ * Lockup debugging
+ */
+
+extern char *video;
+int enable_lockup_debug_dump = 0;
+static unsigned int print_counter;
+unsigned long last_page_fault_from_rip = 0;
+
+static int word_to_hex(char* dest, uint64_t v, int bytes) {
+    static const char* hexdigits = "0123456789abcdef";
+    int i;
+    int n = bytes * 2;
+ 
+    for (i = 0; i < n; i++) {
+      dest[(n-1) - i] = hexdigits[v & 0xf];
+      v >>= 4;
+    }
+
+    return n;
+}
+
+void print_direct_to_screen(const char* buf, int len, int line) {
+    int i;
+    char* dest;
+
+    if (!enable_lockup_debug_dump) return;
+
+    dest = video + (line * 80 * 2);
+
+    for (i = 0; i < len; i++) {
+        dest[i*2 + 0] = buf[i];
+        dest[i*2 + 1] = 7; // white on black
+    }
+}
+
+void print_lockup_debug_dump(struct cpu_user_regs *regs) {
+    char buf[128];
+    char* p;
+    unsigned long cr2;
+    unsigned long cr3;
+    unsigned int flags;
+
+    if (!enable_lockup_debug_dump)
+        return;
+
+    if (!video)
+        return;
+
+    if (!dom0)
+        return;
+
+    print_counter++;
+
+    if ((print_counter & enable_lockup_debug_dump) != 0)
+	return;
+
+    __asm__ __volatile__("mov %%cr2,%0" : "=r" (cr2) : );
+    cr3 = read_cr3();
+    __save_flags(flags);
+
+    memset(buf, ' ', sizeof(buf));
+
+    p = buf;
+    p += word_to_hex(p, regs->rip, 8) + 1;
+    p += word_to_hex(p, cr2, 8) + 1;
+    p += word_to_hex(p, last_page_fault_from_rip, 8) + 1;
+    p += word_to_hex(p, cr3 >> 12, 4) + 1;
+    p += word_to_hex(p, flags, 4) + 1;
+    if (dom0->shared_info) {
+        *p++ = (dom0->shared_info->vcpu_info[0].evtchn_upcall_mask) ? 'M' : '-';
+        *p++ = ' ';
+        *p++ = (dom0->shared_info->vcpu_info[0].evtchn_upcall_pending) ? 'P' : '-';
+        *p++ = ' ';
+        //p += word_to_hex(p, dom0->shared_info->evtchn_mask[0], 2) + 1;
+        //p += word_to_hex(p, dom0->shared_info->evtchn_pending[0], 2) + 1;
+    } else {
+        *p++ = 'X';
+        p++;
+    }
+
+    p += word_to_hex(p, print_counter, 2) + 1;
+
+    print_direct_to_screen(buf, 79, 0);
 }
 
 long arch_do_dom0_op(struct dom0_op *op, XEN_GUEST_HANDLE(dom0_op_t) u_dom0_op)
@@ -438,6 +524,20 @@
     }
     break;
 
+    case DOM0_SET_LOCKUP_DEBUG:
+    {
+        unsigned int enable = op->u.lockupdebug.enable;
+        if (enable) {
+            printk("Enable lockup debugging printout at level %d (old %d, video %p, dom0 %p\n", enable, enable_lockup_debug_dump, video, dom0);
+            enable_lockup_debug_dump = enable;
+        } else {
+            printk("Disable lockup debugging printout\n");
+            enable_lockup_debug_dump = 0;
+        }
+        ret = 0;
+    }
+    break;
+
     default:
         ret = -ENOSYS;
         break;
@@ -458,7 +558,7 @@
     else
     {
         /* IOPL privileges are virtualised: merge back into returned eflags. */
-        BUG_ON((c->user_regs.eflags & EF_IOPL) != 0);
+        //++MTY CHECKME: BUG_ON((c->user_regs.eflags & EF_IOPL) != 0);
         c->user_regs.eflags |= v->arch.iopl << 12;
     }
 
diff -r ea04335d238b xen/arch/x86/domain.c
--- a/xen/arch/x86/domain.c	Thu Aug  3 18:45:14 2006
+++ b/xen/arch/x86/domain.c	Wed Aug 16 04:26:29 2006
@@ -223,6 +223,8 @@
             virt_to_page(d->shared_info), d, XENSHARE_writable);
     }
 
+    d->arch.pt_overlay = NULL;
+
     return 0;
 
  fail_nomem:
@@ -386,6 +388,13 @@
             __copy_to_user(v->runstate_guest, &v->runstate,
                            sizeof(v->runstate));
 
+        break;
+    }
+
+    case VCPUOP_get_registered_runstate_memory_area: {
+        unsigned long runstate_virtaddr = (unsigned long)v->runstate_guest;
+        if (copy_to_guest(arg, &runstate_virtaddr, 1))
+            rc = -EFAULT;
         break;
     }
 
diff -r ea04335d238b xen/arch/x86/mm.c
--- a/xen/arch/x86/mm.c	Thu Aug  3 18:45:14 2006
+++ b/xen/arch/x86/mm.c	Wed Aug 16 04:26:29 2006
@@ -107,6 +107,8 @@
 #include <asm/x86_emulate.h>
 #include <public/memory.h>
 
+extern void print_direct_to_screen(const char* buf, int len, int line);
+
 #ifdef VERBOSE
 #define MEM_LOG(_f, _a...)                                  \
   printk("DOM%u: (file=mm.c, line=%d) " _f "\n",            \
@@ -465,13 +467,14 @@
 
     if ( unlikely(!mfn_valid(page_nr)) || unlikely(!get_page(page, d)) )
     {
-        MEM_LOG("Could not get page ref for pfn %lx", page_nr);
+        printk("get_page_from_pagenr(pagenr %lu, dom %d): mfn valid? %d\n", page_nr, d->domain_id, mfn_valid(page_nr));
         return 0;
     }
 
     return 1;
 }
 
+#define logable(x) (1)
 
 static int get_page_and_type_from_pagenr(unsigned long page_nr, 
                                          unsigned long type,
@@ -479,11 +482,14 @@
 {
     struct page_info *page = mfn_to_page(page_nr);
 
-    if ( unlikely(!get_page_from_pagenr(page_nr, d)) )
+    if ( unlikely(!get_page_from_pagenr(page_nr, d)) ) {
+        if (logable(1)) printk("get_page_and_type_from_pagenr(page_nr %lu, type %lu, dom %p): could not access page_nr\n", page_nr, type, d);
         return 0;
+    }
 
     if ( unlikely(!get_page_type(page, type)) )
     {
+        if (logable(1)) printk("get_page_and_type_from_pagenr(page_nr %lu, type %lu, dom %p): could not get page type\n", page_nr, type, d);
         put_page(page);
         return 0;
     }
@@ -675,7 +681,7 @@
 
     if ( unlikely((l4e_get_flags(l4e) & L4_DISALLOW_MASK)) )
     {
-        MEM_LOG("Bad L4 flags %x", l4e_get_flags(l4e) & L4_DISALLOW_MASK);
+        printk("Bad L4 flags %x", l4e_get_flags(l4e) & L4_DISALLOW_MASK);
         return 0;
     }
 
@@ -796,7 +802,8 @@
     return 1;
 
  fail:
-    MEM_LOG("Failure in alloc_l1_table: entry %d", i);
+    printk("Failure in alloc_l1_table (top mfn %lu): entry %d (target mfn %lu)\n", page_to_mfn(page), i, (unsigned long)((pl1e[i].l1 & 0x7fffffffffffffffULL) >> 12));
+
     while ( i-- > 0 )
         if ( is_guest_l1_slot(i) )
             put_page_from_l1e(pl1e[i], d);
@@ -989,7 +996,8 @@
     return 1;
 
  fail:
-    MEM_LOG("Failure in alloc_l2_table: entry %d", i);
+    printk("Failure in alloc_l2_table (top mfn %lu): entry %d (target mfn %lu)\n", page_to_mfn(page), i, (unsigned long)((pl2e[i].l2 & 0x7fffffffffffffffULL) >> 12));
+
     while ( i-- > 0 )
         if ( is_guest_l2_slot(type, i) )
             put_page_from_l2e(pl2e[i], pfn);
@@ -1050,7 +1058,8 @@
     return 1;
 
  fail:
-    MEM_LOG("Failure in alloc_l3_table: entry %d", i);
+    printk("Failure in alloc_l3_table (top mfn %lu): entry %d (target mfn %lu)\n", page_to_mfn(page), i, (unsigned long)((pl3e[i].l3 & 0x7fffffffffffffffULL) >> 12));
+
     while ( i-- > 0 )
         if ( is_guest_l3_slot(i) )
             put_page_from_l3e(pl3e[i], pfn);
@@ -1079,6 +1088,14 @@
 
     for ( i = 0; i < L4_PAGETABLE_ENTRIES; i++ )
     {
+        if (current->domain->domain_id > 0) {
+            unsigned long targetmfn = l4e_get_pfn(pl4e[i]);
+            if (mfn_valid(targetmfn)) {
+                printk("alloc_l4: mfn %lu slot %d: target mfn %lu: typeinfo %lx\n",
+                       pfn, i, targetmfn, mfn_to_page(targetmfn)->u.inuse.type_info);
+            }
+        }
+
         if ( !l3_backptr(&vaddr, i, type) )
             goto fail;
 
@@ -1101,7 +1118,7 @@
     return 1;
 
  fail:
-    MEM_LOG("Failure in alloc_l4_table: entry %d", i);
+    printk("Failure in alloc_l4_table (top mfn %lu): entry %d (target mfn %lu)\n", page_to_mfn(page), i, (unsigned long)((pl4e[i].l4 & 0x7fffffffffffffffULL) >> 12));
     while ( i-- > 0 )
         if ( is_guest_l4_slot(i) )
             put_page_from_l4e(pl4e[i], pfn);
@@ -1222,8 +1239,10 @@
     l1_pgentry_t ol1e;
     struct domain *d = current->domain;
 
-    if ( unlikely(__copy_from_user(&ol1e, pl1e, sizeof(ol1e)) != 0) )
+    if ( unlikely(__copy_from_user(&ol1e, pl1e, sizeof(ol1e)) != 0) ) {
+        if (logable(1)) printk("mod_l1_entry(pl1e %p, nl1e %016lx): can't copy data\n", pl1e, nl1e.l1);
         return 0;
+    }
 
     if ( unlikely(shadow_mode_refcounts(d)) )
         return update_l1e(pl1e, ol1e, nl1e);
@@ -1232,8 +1251,7 @@
     {
         if ( unlikely(l1e_get_flags(nl1e) & L1_DISALLOW_MASK) )
         {
-            MEM_LOG("Bad L1 flags %x",
-                    l1e_get_flags(nl1e) & L1_DISALLOW_MASK);
+            if (logable(1)) printk("mod_l1_entry(pl1e %p, nl1e %016lx): bad L1 flags %x\n", pl1e, nl1e.l1, l1e_get_flags(nl1e) & L1_DISALLOW_MASK);
             return 0;
         }
 
@@ -1241,19 +1259,24 @@
         if ( !l1e_has_changed(ol1e, nl1e, _PAGE_RW | _PAGE_PRESENT))
             return update_l1e(pl1e, ol1e, nl1e);
 
-        if ( unlikely(!get_page_from_l1e(nl1e, FOREIGNDOM)) )
+        if ( unlikely(!get_page_from_l1e(nl1e, FOREIGNDOM)) ) {
+            if (logable(1)) printk("mod_l1_entry(pl1e %p, nl1e %016lx): can't get page from foreigndom %p\n", pl1e, nl1e.l1, FOREIGNDOM);
             return 0;
+        }
         
         if ( unlikely(!update_l1e(pl1e, ol1e, nl1e)) )
         {
+            if (logable(1)) printk("mod_l1_entry(pl1e %p, nl1e %016lx): problem doing L1 update\n", pl1e, nl1e.l1);
             put_page_from_l1e(nl1e, d);
             return 0;
         }
     }
     else
     {
-        if ( unlikely(!update_l1e(pl1e, ol1e, nl1e)) )
+        if ( unlikely(!update_l1e(pl1e, ol1e, nl1e)) ) {
+            if (logable(1)) printk("mod_l1_entry(pl1e %p, nl1e %016lx): problem doing not-present L1 update\n", pl1e, nl1e.l1);
             return 0;
+        }
     }
 
     put_page_from_l1e(ol1e, d);
@@ -1290,19 +1313,20 @@
 
     if ( unlikely(!is_guest_l2_slot(type,pgentry_ptr_to_slot(pl2e))) )
     {
-        MEM_LOG("Illegal L2 update attempt in Xen-private area %p", pl2e);
+        if (logable(1)) printk("mod_l2_entry(pl2e %p, nl2e %016lx, pfn %lu, type %lu): illegal access in Xen-private area\n", pl2e, nl2e.l2, pfn, type);
         return 0;
     }
 
-    if ( unlikely(__copy_from_user(&ol2e, pl2e, sizeof(ol2e)) != 0) )
+    if ( unlikely(__copy_from_user(&ol2e, pl2e, sizeof(ol2e)) != 0) ) {
+        if (logable(1)) printk("mod_l2_entry(pl2e %p, nl2e %016lx, pfn %lu, type %lu): can't copy from user\n", pl2e, nl2e.l2, pfn, type);
         return 0;
+    }
 
     if ( l2e_get_flags(nl2e) & _PAGE_PRESENT )
     {
         if ( unlikely(l2e_get_flags(nl2e) & L2_DISALLOW_MASK) )
         {
-            MEM_LOG("Bad L2 flags %x",
-                    l2e_get_flags(nl2e) & L2_DISALLOW_MASK);
+            if (logable(1)) printk("mod_l2_entry(pl2e %p, nl2e %016lx, pfn %lu, type %lu): bad flags %x\n", pl2e, nl2e.l2, pfn, type, l2e_get_flags(nl2e) & L2_DISALLOW_MASK);
             return 0;
         }
 
@@ -1311,17 +1335,21 @@
             return UPDATE_ENTRY(l2, pl2e, ol2e, nl2e);
 
         if ( unlikely(!l1_backptr(&vaddr, pgentry_ptr_to_slot(pl2e), type)) ||
-             unlikely(!get_page_from_l2e(nl2e, pfn, current->domain, vaddr)) )
+             unlikely(!get_page_from_l2e(nl2e, pfn, current->domain, vaddr)) ) {
+            if (logable(1)) printk("mod_l2_entry(pl2e %p, nl2e %016lx, pfn %lu, type %lu): problem getting backptr or page\n", pl2e, nl2e.l2, pfn, type);
             return 0;
+        }
 
         if ( unlikely(!UPDATE_ENTRY(l2, pl2e, ol2e, nl2e)) )
         {
+            if (logable(1)) printk("mod_l2_entry(pl2e %p, nl2e %016lx, pfn %lu, type %lu): problem doing update\n", pl2e, nl2e.l2, pfn, type);
             put_page_from_l2e(nl2e, pfn);
             return 0;
         }
     }
     else if ( unlikely(!UPDATE_ENTRY(l2, pl2e, ol2e, nl2e)) )
     {
+        if (logable(1)) printk("mod_l2_entry(pl2e %p, nl2e %016lx, pfn %lu, type %lu): problem doing not-present update\n", pl2e, nl2e.l2, pfn, type);
         return 0;
     }
 
@@ -1344,7 +1372,7 @@
 
     if ( unlikely(!is_guest_l3_slot(pgentry_ptr_to_slot(pl3e))) )
     {
-        MEM_LOG("Illegal L3 update attempt in Xen-private area %p", pl3e);
+        if (logable(1)) printk("mod_l3_entry(pl3e %p, nl3e %016lx, pfn %lu, type %lu): illegal access in Xen-private area\n", pl3e, nl3e.l3, pfn, type);
         return 0;
     }
 
@@ -1357,15 +1385,16 @@
         return 0;
 #endif
 
-    if ( unlikely(__copy_from_user(&ol3e, pl3e, sizeof(ol3e)) != 0) )
+    if ( unlikely(__copy_from_user(&ol3e, pl3e, sizeof(ol3e)) != 0) ) {
+        if (logable(1)) printk("mod_l3_entry(pl3e %p, nl3e %016lx, pfn %lu, type %lu): can't copy from user\n", pl3e, nl3e.l3, pfn, type);
         return 0;
+    }
 
     if ( l3e_get_flags(nl3e) & _PAGE_PRESENT )
     {
         if ( unlikely(l3e_get_flags(nl3e) & L3_DISALLOW_MASK) )
         {
-            MEM_LOG("Bad L3 flags %x",
-                    l3e_get_flags(nl3e) & L3_DISALLOW_MASK);
+            if (logable(1)) printk("mod_l3_entry(pl3e %p, nl3e %016lx, pfn %lu, type %lu): bad flags %x\n", pl3e, nl3e.l3, pfn, type, l3e_get_flags(nl3e) & L3_DISALLOW_MASK);
             return 0;
         }
 
@@ -1375,23 +1404,29 @@
 
 #if CONFIG_PAGING_LEVELS >= 4
         if ( unlikely(!l2_backptr(&vaddr, pgentry_ptr_to_slot(pl3e), type)) ||
-             unlikely(!get_page_from_l3e(nl3e, pfn, current->domain, vaddr)) )
+             unlikely(!get_page_from_l3e(nl3e, pfn, current->domain, vaddr)) ) {
+            if (logable(1)) printk("mod_l3_entry(pl3e %p, nl3e %016lx, pfn %lu, type %lu): problem getting backptr or page\n", pl3e, nl3e.l3, pfn, type);
             return 0; 
+        }
 #else
         vaddr = (((unsigned long)pl3e & ~PAGE_MASK) / sizeof(l3_pgentry_t))
             << L3_PAGETABLE_SHIFT;
-        if ( unlikely(!get_page_from_l3e(nl3e, pfn, current->domain, vaddr)) )
+        if ( unlikely(!get_page_from_l3e(nl3e, pfn, current->domain, vaddr)) ) {
+            if (logable(1)) printk("mod_l3_entry(pl3e %p, nl3e %016lx, pfn %lu, type %lu): problem getting page from l3e\n", pl3e, nl3e.l3, pfn, type);
             return 0;
+        }
 #endif
 
         if ( unlikely(!UPDATE_ENTRY(l3, pl3e, ol3e, nl3e)) )
         {
+            if (logable(1)) printk("mod_l3_entry(pl3e %p, nl3e %016lx, pfn %lu, type %lu): can't update entry\n", pl3e, nl3e.l3, pfn, type);
             put_page_from_l3e(nl3e, pfn);
             return 0;
         }
     }
     else if ( unlikely(!UPDATE_ENTRY(l3, pl3e, ol3e, nl3e)) )
     {
+        if (logable(1)) printk("mod_l3_entry(pl3e %p, nl3e %016lx, pfn %lu, type %lu): can't update not-present entry\n", pl3e, nl3e.l3, pfn, type);
         return 0;
     }
 
@@ -1419,19 +1454,20 @@
 
     if ( unlikely(!is_guest_l4_slot(pgentry_ptr_to_slot(pl4e))) )
     {
-        MEM_LOG("Illegal L4 update attempt in Xen-private area %p", pl4e);
+        if (logable(1)) printk("mod_l4_entry(pl4e %p, nl4e %016lx, pfn %lu, type %lu): illegal access in Xen-private area\n", pl4e, nl4e.l4, pfn, type);
         return 0;
     }
 
-    if ( unlikely(__copy_from_user(&ol4e, pl4e, sizeof(ol4e)) != 0) )
+    if ( unlikely(__copy_from_user(&ol4e, pl4e, sizeof(ol4e)) != 0) ) {
+        if (logable(1)) printk("mod_l4_entry(pl4e %p, nl4e %016lx, pfn %lu, type %lu): can't copy from user\n", pl4e, nl4e.l4, pfn, type);
         return 0;
+    }
 
     if ( l4e_get_flags(nl4e) & _PAGE_PRESENT )
     {
         if ( unlikely(l4e_get_flags(nl4e) & L4_DISALLOW_MASK) )
         {
-            MEM_LOG("Bad L4 flags %x",
-                    l4e_get_flags(nl4e) & L4_DISALLOW_MASK);
+            if (logable(1)) printk("mod_l4_entry(pl4e %p, nl4e %016lx, pfn %lu, type %lu): bad L4 flags %x\n", pl4e, nl4e.l4, pfn, type, l4e_get_flags(nl4e) & L4_DISALLOW_MASK);
             return 0;
         }
 
@@ -1440,17 +1476,21 @@
             return UPDATE_ENTRY(l4, pl4e, ol4e, nl4e);
 
         if ( unlikely(!l3_backptr(&vaddr, pgentry_ptr_to_slot(pl4e), type)) ||
-             unlikely(!get_page_from_l4e(nl4e, pfn, current->domain, vaddr)) )
+             unlikely(!get_page_from_l4e(nl4e, pfn, current->domain, vaddr)) ) {
+            if (logable(1)) printk("mod_l4_entry(pl4e %p, nl4e %016lx, pfn %lu, type %lu): problem getting back pointer or page\n", pl4e, nl4e.l4, pfn, type);
             return 0;
+        }
 
         if ( unlikely(!UPDATE_ENTRY(l4, pl4e, ol4e, nl4e)) )
         {
+            if (logable(1)) printk("mod_l4_entry(pl4e %p, nl4e %016lx, pfn %lu, type %lu): problem updating entry\n", pl4e, nl4e.l4, pfn, type);
             put_page_from_l4e(nl4e, pfn);
             return 0;
         }
     }
     else if ( unlikely(!UPDATE_ENTRY(l4, pl4e, ol4e, nl4e)) )
     {
+        if (logable(1)) printk("mod_l4_entry(pl4e %p, nl4e %016lx, pfn %lu, type %lu): problem updating not-present entry\n", pl4e, nl4e.l4, pfn, type);
         return 0;
     }
 
@@ -1614,7 +1654,7 @@
         nx = x + 1;
         if ( unlikely((nx & PGT_count_mask) == 0) )
         {
-            MEM_LOG("Type count overflow on pfn %lx", page_to_mfn(page));
+            if (logable(1)) printk("get_page_type(mfn %lu, type %lu): type count overflow (nx = %lu)\n", page_to_mfn(page), type, nx);
             return 0;
         }
         else if ( unlikely((x & PGT_count_mask) == 0) )
@@ -1652,6 +1692,8 @@
         }
         else
         {
+            /* The type count is non-zero: some existing refs to this type, so we can't change the page type yet */
+
             if ( unlikely((x & (PGT_type_mask|PGT_va_mask)) != type) )
             {
                 if ( unlikely((x & PGT_type_mask) != (type & PGT_type_mask) ) )
@@ -1678,13 +1720,21 @@
                              ((y & PGT_count_mask) == 0) )
                             goto again;
                     }
-                    if ( ((x & PGT_type_mask) != PGT_l2_page_table) ||
-                         ((type & PGT_type_mask) != PGT_l1_page_table) )
-                        MEM_LOG("Bad type (saw %" PRtype_info
-                                " != exp %" PRtype_info ") "
-                                "for mfn %lx (pfn %lx)",
-                                x, type, page_to_mfn(page),
-                                get_gpfn_from_mfn(page_to_mfn(page)));
+                    //if ( ((x & PGT_type_mask) != PGT_l2_page_table) ||
+                    //((type & PGT_type_mask) != PGT_l1_page_table) )
+                    if (logable(1)) {
+                        printk("get_page_type(mfn %lu, type %lu): "
+                               "Bad type (saw %" PRtype_info
+                               " != exp %" PRtype_info ") "
+                               "for mfn %lu (pfn %lu); "
+                               "typecount %d\n",
+                               page_to_mfn(page), type,
+                               x, type, page_to_mfn(page),
+                               get_gpfn_from_mfn(page_to_mfn(page)),
+                               (int)(x & PGT_count_mask));
+                   
+                        printk("get_page_type(mfn %lu, type %lu): returning 0\n", page_to_mfn(page), type);
+                    }
                     return 0;
                 }
                 else if ( (x & PGT_va_mask) == PGT_va_mutable )
@@ -1698,13 +1748,18 @@
                     ASSERT((type & PGT_va_mask) != (x & PGT_va_mask));
 #ifdef CONFIG_X86_PAE
                     /* We use backptr as extra typing. Cannot be unknown. */
-                    if ( (type & PGT_type_mask) == PGT_l2_page_table )
+                    if ( (type & PGT_type_mask) == PGT_l2_page_table ) {
+                        if (logable(1)) printk("get_page_type(mfn %lu, type %lu): type is %lu, is l2_page_table\n", page_to_mfn(page), type);
                         return 0;
+                    }
 #endif
                     /* Fixme: add code to propagate va_unknown to subtables. */
                     if ( ((type & PGT_type_mask) >= PGT_l2_page_table) &&
-                         !shadow_mode_refcounts(page_get_owner(page)) )
+                         !shadow_mode_refcounts(page_get_owner(page)) ) {
+                        if (logable(1)) printk("get_page_type(mfn %lu, type %lu): type is %lu, refcounts %u\n",
+                               page_to_mfn(page), type, (type & PGT_type_mask), shadow_mode_refcounts(page_get_owner(page)));
                         return 0;
+                    }
                     /* This table is possibly mapped at multiple locations. */
                     nx &= ~PGT_va_mask;
                     nx |= PGT_va_unknown;
@@ -1726,10 +1781,12 @@
         /* Try to validate page type; drop the new reference on failure. */
         if ( unlikely(!alloc_page_type(page, type)) )
         {
-            MEM_LOG("Error while validating mfn %lx (pfn %lx) for type %"
-                    PRtype_info ": caf=%08x taf=%" PRtype_info,
-                    page_to_mfn(page), get_gpfn_from_mfn(page_to_mfn(page)),
-                    type, page->count_info, page->u.inuse.type_info);
+            if (logable(1)) printk("get_page_type(mfn %lu, type %lu): "
+                   "Error while validating mfn %lu (pfn %lu) for type %"
+                   PRtype_info ": caf=%08x taf=%" PRtype_info "\n",
+                   page_to_mfn(page), type,
+                   page_to_mfn(page), get_gpfn_from_mfn(page_to_mfn(page)),
+                   type, page->count_info, page->u.inuse.type_info);
             /* Noone else can get a reference. We hold the only ref. */
             page->u.inuse.type_info = 0;
             return 0;
@@ -1743,9 +1800,8 @@
 }
 
 
-int new_guest_cr3(unsigned long mfn)
-{
-    struct vcpu *v = current;
+int update_vcpu_pt_base(struct vcpu *v, unsigned long mfn, int update_cr3)
+{
     struct domain *d = v->domain;
     int okay;
     unsigned long old_base_mfn;
@@ -1764,13 +1820,18 @@
     else
     {
         okay = get_page_and_type_from_pagenr(mfn, PGT_root_page_table, d);
+        if ( unlikely((!okay) && (!update_cr3)) ) {
+            printk("Cannot install new baseptr %lu for vcpu %d in domain %d: not pinned as a root page table\n", mfn, v->vcpu_id, d->domain_id);
+            return 0;
+        }
+
         if ( unlikely(!okay) )
         {
             /* Switch to idle pagetable: this VCPU has no active p.t. now. */
             old_base_mfn = pagetable_get_pfn(v->arch.guest_table);
             v->arch.guest_table = pagetable_null();
             update_pagetables(v);
-            write_cr3(__pa(idle_pg_table));
+            if (update_cr3) write_cr3(__pa(idle_pg_table));
             if ( old_base_mfn != 0 )
                 put_page_and_type(mfn_to_page(old_base_mfn));
 
@@ -1779,8 +1840,7 @@
             if ( !okay )
             {
                 /* Failure here is unrecoverable: the VCPU has no pagetable! */
-                MEM_LOG("Fatal error while installing new baseptr %lx", mfn);
-                domain_crash(d);
+                printk("Fatal error while installing new baseptr %lu for vcpu %d in domain %d\n", mfn, v->vcpu_id, d->domain_id);
                 percpu_info[v->processor].deferred_ops = 0;
                 return 0;
             }
@@ -1793,7 +1853,7 @@
     v->arch.guest_table = pagetable_from_pfn(mfn);
     update_pagetables(v); /* update shadow_table and monitor_table */
 
-    write_ptbase(v);
+    if (update_cr3) write_ptbase(v);
 
     if ( likely(old_base_mfn != 0) )
     {
@@ -1921,6 +1981,99 @@
     return pmask;
 }
 
+extern int enable_lockup_debug_dump;
+
+/*
+ * Inject an entry into the toplevel page table if one exists in the overlay
+ * table and the toplevel slot PTE was not present.
+ *
+ * The domain's biglock should NOT be held before calling this.
+ */
+int fixup_overlay_page_fault(unsigned long addr, struct cpu_user_regs *regs) {
+    unsigned long mfn;
+    unsigned long cr3;
+    l4_pgentry_t l4e;
+    l4_pgentry_t* l4t;
+    l4_pgentry_t overl4e;
+    struct domain* d = current->domain;
+    void* va;
+    struct page_info* page;
+    unsigned long type_info;
+    int slot;
+    int ok = 0;
+
+    slot = l4_table_offset(addr);
+
+    if (shadow_mode_enabled(d)) {
+        /* This doesn't work in shadow mode */
+        return 0;
+    }
+
+    LOCK_BIGLOCK(d);
+    cleanup_writable_pagetable(d);
+
+    if (!d->arch.pt_overlay) {
+        UNLOCK_BIGLOCK(d);
+        return 0;
+    }
+
+    overl4e = current->domain->arch.pt_overlay[slot];
+
+    UNLOCK_BIGLOCK(d);
+
+    cr3 = read_cr3();
+    mfn = cr3 >> PAGE_SHIFT;
+    l4t = map_domain_page(mfn);
+    l4e = l4t[slot];
+
+    /*
+     * If the page is already present, some other protection problem
+     * prevented our access to this page. We must pass the fault back
+     * up to the guest kernel since otherwise we could get into an
+     * infinite loop in case the guest passes a bogus overlay PTE.
+     */
+    if (l4e_get_flags(l4e) & _PAGE_PRESENT) {
+        unmap_domain_page(l4t);
+        return 0;
+    }
+
+    /* Overlay L4e not present: cannot do overlay */
+    if (!(l4e_get_flags(overl4e) & _PAGE_PRESENT)) {
+        unmap_domain_page(l4t);
+        return 0;
+    }
+
+    LOCK_BIGLOCK(d);
+
+    if (unlikely(!get_page_from_pagenr(mfn, d))) {
+        printk("fixup_overlay_page_fault: could not get mfn %lu in domain %d\n", mfn, d->domain_id);
+        goto out;
+    }
+
+    va = &l4t[slot];
+    page = mfn_to_page(mfn);
+
+    type_info = page->u.inuse.type_info;
+    /* It must be an L4 table or it wouldn't currently be in cr3 */
+    ASSERT((type_info & PGT_type_mask) == PGT_l4_page_table);
+    ASSERT(!shadow_mode_refcounts(d));
+    ASSERT(get_page_type(page, type_info & (PGT_type_mask|PGT_va_mask)));
+                
+    ok = mod_l4_entry(va, overl4e, mfn, type_info);
+
+    printk("fixup_overlay_page_fault: injected L3 mfn %lu into mfn %lu offset %d in domain %d: ok? %d\n", overl4e.l4 >> 12, mfn, slot, d->domain_id, ok);
+                
+    put_page_type(page);
+    put_page(page);
+
+    flush_tlb_mask(d->domain_dirty_cpumask);
+  out:
+
+    UNLOCK_BIGLOCK(d);
+    unmap_domain_page(l4t);
+    return ok;
+}
+
 int do_mmuext_op(
     XEN_GUEST_HANDLE(mmuext_op_t) uops,
     unsigned int count,
@@ -1998,17 +2151,32 @@
             if ( shadow_mode_refcounts(FOREIGNDOM) )
                 break;
 
+            if (current->domain->domain_id > 0) {
+                if (mfn_valid(mfn)) {
+                    l4_pgentry_t* pl4e;
+                    unsigned long targetmfn;
+                    unsigned long typeinfo = mfn_to_page(mfn)->u.inuse.type_info;
+                    printk("Pin mfn %lu: before getting page type, type count is %lx\n", mfn, typeinfo);
+
+                    pl4e = page_to_virt(mfn_to_page(mfn));
+                    targetmfn = l4e_get_pfn(pl4e[0]);
+                    if (mfn_valid(targetmfn)) {
+                        typeinfo = mfn_to_page(targetmfn)->u.inuse.type_info;
+                        printk("Slot 0 target mfn %lu: type count is %lx\n", targetmfn, typeinfo);
+                    }
+                }
+            }
             okay = get_page_and_type_from_pagenr(mfn, type, FOREIGNDOM);
             if ( unlikely(!okay) )
             {
-                MEM_LOG("Error while pinning mfn %lx", mfn);
+                printk("Error while pinning mfn %lu", mfn);
                 break;
             }
             
             if ( unlikely(test_and_set_bit(_PGT_pinned,
                                            &page->u.inuse.type_info)) )
             {
-                MEM_LOG("Mfn %lx already pinned", mfn);
+                printk("mfn %lu already pinned", mfn);
                 put_page_and_type(page);
                 okay = 0;
                 break;
@@ -2144,6 +2312,208 @@
             break;
         }
 
+        /*
+         * PTLsim specific hypercalls
+         */
+
+        /* Get template GDT mapped by Xen into the FIRST_RESERVED_GDT_PAGE gdt_frames[] slot */
+
+        case MMUEXT_GET_GDT_TEMPLATE: {       
+            rc = -E2BIG;
+            if (op.arg2.nr_ents > PAGE_SIZE)
+                break;
+            
+            rc = -EFAULT;
+            if (copy_to_user((void*)op.arg1.linear_addr, &gdt_table, op.arg2.nr_ents))
+                break;
+            
+            rc = 0;
+            break;
+        }
+
+        /* New kernel or user page table base pointer for foreign domain's specified VCPU(s) */
+        case MMUEXT_SET_KERNEL_BASEPTR:
+        case MMUEXT_SET_USER_BASEPTR: {
+            struct vcpu *v;
+
+            rc = -EPERM;
+            /* Technically only dom0 can use this call since it can't specify itself */
+            if (FOREIGNDOM == current->domain)
+                /* Can't do this to ourselves */
+                break;
+
+            rc = -E2BIG;
+            if ((op.arg2.vcpuid < 0) || (op.arg2.vcpuid >= MAX_VIRT_CPUS))
+                break;
+
+            rc = -ENOENT;
+            if ((v = FOREIGNDOM->vcpu[op.arg2.vcpuid]) == NULL)
+                break;
+
+            if (op.cmd == MMUEXT_SET_KERNEL_BASEPTR) {
+                okay = update_vcpu_pt_base(v, mfn, 0);
+                if (unlikely(!okay)) {
+                    printk("Error while installing new mfn %lu as kernel baseptr in domain %d on vcpu %d\n",
+                           mfn, FOREIGNDOM->domain_id, v->vcpu_id);
+                    rc = -EINVAL;
+                    break;
+                }
+
+                /*
+                 * Technically the domain should be paused before doing this call
+                 * since the results are undefined otherwise. However, even if paused,
+                 * we still need to reload the TLB on all CPUs touched by this VCPU
+                 * in case they are actually paused with the old page table base
+                 * loaded into CR3 instead of the idle page table.
+                 */
+                flush_tlb_mask(v->vcpu_dirty_cpumask);
+            } else {
+                /* Set user base pointer */
+                okay = get_page_and_type_from_pagenr(mfn, PGT_root_page_table, FOREIGNDOM);
+                if (unlikely(!okay)) {
+                    printk("Error while installing new mfn %lu as user baseptr in domain %d on vcpu %d\n",
+                           mfn, FOREIGNDOM->domain_id, v->vcpu_id);
+                    rc = -EINVAL;
+                    break;
+                } else {
+                    unsigned long old_mfn = pagetable_get_pfn(v->arch.guest_table_user);
+                    v->arch.guest_table_user = pagetable_from_pfn(mfn);
+                    if ( old_mfn != 0 )
+                        put_page_and_type(mfn_to_page(old_mfn));
+                }
+
+                /*
+                 * TLB flush is not needed here since the user tables 
+                 * will get reloaded on return from kernel mode anyway.
+                 */
+            }
+
+            rc = 0;
+            break;
+        }
+
+        case MMUEXT_GET_KERNEL_BASEPTR:
+        case MMUEXT_GET_USER_BASEPTR: {
+            struct vcpu *v;
+
+            rc = -E2BIG;
+            if ((op.arg2.vcpuid < 0) || (op.arg2.vcpuid >= MAX_VIRT_CPUS))
+                break;
+
+            rc = -ENOENT;
+            if ((v = FOREIGNDOM->vcpu[op.arg2.vcpuid]) == NULL)
+                break;
+
+            mfn = (op.cmd == MMUEXT_GET_KERNEL_BASEPTR)
+                ? pagetable_get_pfn(v->arch.guest_table)
+                : pagetable_get_pfn(v->arch.guest_table_user);
+
+            rc = -EFAULT;
+            if (copy_to_user((void*)op.arg1.linear_addr, &mfn, sizeof(mfn)))
+                break;
+
+            rc = 0;
+            break;            
+        }
+
+        case MMUEXT_SET_PT_OVERLAY: {
+            l4_pgentry_t* ptoverlay = NULL;
+            l4_pgentry_t* old_ptoverlay = NULL;
+
+            printk("Setting PT overlay for domain %d: virt addr %p\n", FOREIGNDOM->domain_id, (void*)op.arg1.linear_addr);
+
+            if (FOREIGNDOM != current->domain) LOCK_BIGLOCK(FOREIGNDOM);
+
+            if (op.arg1.linear_addr) {
+                if (!(ptoverlay = (l4_pgentry_t*)alloc_xenheap_page())) {
+                    if (FOREIGNDOM != current->domain) UNLOCK_BIGLOCK(FOREIGNDOM);
+                    rc = -ENOMEM;
+                    break;
+                }
+
+                printk("Allocated Xen virt addr %p for PT overlay\n", ptoverlay);
+
+                if ((rc = copy_from_user(ptoverlay, (void*)op.arg1.linear_addr, PAGE_SIZE)) != 0) {
+                    printk("Can't access PT overlay virt addr %p\n", (void*)op.arg1.linear_addr);
+                    free_xenheap_page(ptoverlay);
+                    if (FOREIGNDOM != current->domain) UNLOCK_BIGLOCK(FOREIGNDOM);
+                    rc = -EFAULT;
+                    break;
+                }
+            }
+
+            old_ptoverlay = cmpxchg(&FOREIGNDOM->arch.pt_overlay, old_ptoverlay, ptoverlay);
+
+            if (old_ptoverlay) {
+                printk("Free old PT overlay virt addr %p\n", old_ptoverlay);
+                free_xenheap_page(old_ptoverlay);
+            }
+
+            if (FOREIGNDOM != current->domain) UNLOCK_BIGLOCK(FOREIGNDOM);
+
+            okay = 1;
+            rc = 0;
+
+            break;
+        }
+
+        case MMUEXT_QUERY_PAGES: {
+            page_type_t* ptr = (page_type_t*)op.arg1.linear_addr;
+            page_type_t pagetype;
+            unsigned long mfn;
+            int i;
+
+            rc = 0;
+            okay = 0;
+            for (i = 0; i < op.arg2.nr_ents; i++) {
+                rc = -EFAULT;
+                if (unlikely(copy_from_user(&pagetype, &ptr[i], sizeof(page_type_t))))
+                    break;
+
+                mfn = pagetype.in.mfn;
+                pagetype.out.type = PAGE_TYPE_INVALID_MFN;
+                pagetype.out.pinned = 0;
+                pagetype.out.type_count = 0;
+                pagetype.out.total_count = 0;
+
+                if (likely(mfn_valid(mfn))) {
+                    page = mfn_to_page(mfn);
+                    if (likely(get_page(page, FOREIGNDOM))) {
+                        int type = PAGE_TYPE_NONE;
+                        switch (page->u.inuse.type_info & PGT_type_mask) {
+                        case PGT_none: type = PAGE_TYPE_NONE; break;
+                        case PGT_l1_page_table: type = PAGE_TYPE_L1; break;
+                        case PGT_l2_page_table: type = PAGE_TYPE_L2; break;
+                        case PGT_l3_page_table: type = PAGE_TYPE_L3; break;
+                        case PGT_l4_page_table: type = PAGE_TYPE_L4; break;
+                        case PGT_gdt_page: type = PAGE_TYPE_GDT; break;
+                        case PGT_ldt_page: type = PAGE_TYPE_LDT; break;
+                        case PGT_writable_page: type = PAGE_TYPE_WRITABLE; break;
+                        default: type = PAGE_TYPE_NONE; break;
+                        }
+
+                        pagetype.out.type = type;
+                        pagetype.out.pinned = ((page->u.inuse.type_info & PGT_pinned) != 0);
+                        pagetype.out.type_count = page->u.inuse.type_info & PGT_count_mask;
+                        pagetype.out.total_count = page->count_info & PGC_count_mask;
+                        put_page(page);
+                    } else {
+                        pagetype.out.type = PAGE_TYPE_INACCESSIBLE;
+                    }
+                }
+
+                rc = -EFAULT;
+                if (unlikely(copy_to_user(&ptr[i], &pagetype, sizeof(page_type_t))))
+                    break;
+
+                rc = 0;
+            }
+
+            okay = (rc == 0);
+
+            break;
+        }
+
         default:
             MEM_LOG("Invalid extended pt command 0x%x", op.cmd);
             okay = 0;
@@ -2170,6 +2540,7 @@
     UNLOCK_BIGLOCK(d);
     return rc;
 }
+
 
 int do_mmu_update(
     XEN_GUEST_HANDLE(mmu_update_t) ureqs,
@@ -2207,6 +2578,7 @@
 
     if ( !set_foreigndom(cpu, foreigndom) )
     {
+        if (logable(1)) printk("mmu_update (domain %d): can't access foreigndom %d\n", d->domain_id, foreigndom);
         rc = -ESRCH;
         goto out;
     }
@@ -2217,6 +2589,7 @@
 
     if ( unlikely(!guest_handle_okay(ureqs, count)) )
     {
+        if (logable(1)) printk("mmu_update (domain %d): can't access guest pointer %p\n", d->domain_id, ureqs.p);
         rc = -EFAULT;
         goto out;
     }
@@ -2234,6 +2607,7 @@
         if ( unlikely(__copy_from_guest(&req, ureqs, 1) != 0) )
         {
             MEM_LOG("Bad __copy_from_guest");
+            if (logable(1)) printk("mmu_update (domain %d): can't read from guest pointer %p\n", d->domain_id, ureqs.p);
             rc = -EFAULT;
             break;
         }
@@ -2253,7 +2627,7 @@
 
             if ( unlikely(!get_page_from_pagenr(mfn, current->domain)) )
             {
-                MEM_LOG("Could not get page for normal update");
+                if (logable(1)) printk("mmu_update (domain %d, foreigndom %d, mfn %lu): can't get page from pagenr\n", d->domain_id, FOREIGNDOM->domain_id, mfn);
                 break;
             }
 
@@ -2270,9 +2644,10 @@
             case PGT_l4_page_table:
             {
                 ASSERT(!shadow_mode_refcounts(d));
-                if ( unlikely(!get_page_type(
-                    page, type_info & (PGT_type_mask|PGT_va_mask))) )
+                if ( unlikely(!get_page_type(page, type_info & (PGT_type_mask|PGT_va_mask))) ) { 
+                    if (logable(1)) printk("mmu_update (domain %d, mfn %lu): is not a PT page (type is %lu)\n", d->domain_id, mfn, type_info);
                     goto not_a_pt;
+                }
 
                 switch ( type_info & PGT_type_mask )
                 {
@@ -2326,8 +2701,10 @@
             default:
             not_a_pt:
             {
-                if ( unlikely(!get_page_type(page, PGT_writable_page)) )
+                if ( unlikely(!get_page_type(page, PGT_writable_page)) ) {
+                    if (logable(1)) printk("mmu_update (domain %d, mfn %lu): can't get page writable type\n", d->domain_id, mfn);
                     break;
+                }
 
                 if ( shadow_mode_enabled(d) )
                 {
diff -r ea04335d238b xen/arch/x86/setup.c
--- a/xen/arch/x86/setup.c	Thu Aug  3 18:45:14 2006
+++ b/xen/arch/x86/setup.c	Wed Aug 16 04:26:29 2006
@@ -632,7 +632,7 @@
 
 #elif defined(CONFIG_X86_64)
 
-    p += sprintf(p, "xen-%d.%d-x86_64 ", major, minor);
+    p += sprintf(p, "xen-%d.%d-x86_64-ptlsim ", major, minor);
     if ( hvm_enabled )
     {
         p += sprintf(p, "hvm-%d.%d-x86_32 ", major, minor);
diff -r ea04335d238b xen/arch/x86/time.c
--- a/xen/arch/x86/time.c	Thu Aug  3 18:45:14 2006
+++ b/xen/arch/x86/time.c	Wed Aug 16 04:26:29 2006
@@ -143,12 +154,20 @@
     return product;
 }
 
+extern int enable_lockup_debug_dump;
+extern void print_lockup_debug_dump(struct cpu_user_regs *regs);
+
+extern unsigned char *video;
+
 void timer_interrupt(int irq, void *dev_id, struct cpu_user_regs *regs)
 {
     ASSERT(local_irq_is_enabled());
 
     /* Update jiffies counter. */
     (*(unsigned long *)&jiffies)++;
+
+    if (enable_lockup_debug_dump)
+        print_lockup_debug_dump(regs);
 
     /* Rough hack to allow accurate timers to sort-of-work with no APIC. */
     if ( !cpu_has_apic )
diff -r ea04335d238b xen/arch/x86/traps.c
--- a/xen/arch/x86/traps.c	Thu Aug  3 18:45:14 2006
+++ b/xen/arch/x86/traps.c	Wed Aug 16 04:26:29 2006
@@ -45,6 +45,7 @@
 #include <xen/iocap.h>
 #include <xen/nmi.h>
 #include <xen/version.h>
+#include <xen/trace.h>
 #include <asm/shadow.h>
 #include <asm/system.h>
 #include <asm/io.h>
@@ -780,7 +781,7 @@
     l4e = l4t[l4_table_offset(addr)];
     mfn = l4e_get_pfn(l4e);
     unmap_domain_page(l4t);
-    if ( !(l4e_get_flags(l4e) & required_flags) ||
+    if ( ((l4e_get_flags(l4e) & required_flags) != required_flags) ||
          (l4e_get_flags(l4e) & disallowed_flags) )
         return 0;
 #endif
@@ -797,7 +798,7 @@
     if ( !(l3e_get_flags(l3e) & _PAGE_PRESENT) )
         return 0;
 #else
-    if ( !(l3e_get_flags(l3e) & required_flags) ||
+    if ( ((l3e_get_flags(l3e) & required_flags) != required_flags) ||
          (l3e_get_flags(l3e) & disallowed_flags) )
         return 0;
 #endif
@@ -807,7 +808,7 @@
     l2e = l2t[l2_table_offset(addr)];
     mfn = l2e_get_pfn(l2e);
     unmap_domain_page(l2t);
-    if ( !(l2e_get_flags(l2e) & required_flags) ||
+    if ( ((l2e_get_flags(l2e) & required_flags) != required_flags) ||
          (l2e_get_flags(l2e) & disallowed_flags) )
         return 0;
     if ( l2e_get_flags(l2e) & _PAGE_PSE )
@@ -820,7 +821,7 @@
     l1e = l1t[l1_table_offset(addr)];
     mfn = l1e_get_pfn(l1e);
     unmap_domain_page(l1t);
-    if ( !(l1e_get_flags(l1e) & required_flags) ||
+    if ( ((l1e_get_flags(l1e) & required_flags) != required_flags) ||
          (l1e_get_flags(l1e) & disallowed_flags) )
         return 0;
 
@@ -856,6 +857,8 @@
     return is_spurious;
 }
 
+int fixup_overlay_page_fault(unsigned long addr, struct cpu_user_regs *regs);
+
 static int fixup_page_fault(unsigned long addr, struct cpu_user_regs *regs)
 {
     struct vcpu   *v = current;
@@ -878,6 +881,9 @@
     if ( unlikely(shadow_mode_enabled(d)) )
         return shadow_fault(addr, regs);
 
+    if ( unlikely(fixup_overlay_page_fault(addr, regs)) )
+        return EXCRET_fault_fixed;
+
     if ( likely(VM_ASSIST(d, VMASST_TYPE_writable_pagetables)) )
     {
         LOCK_BIGLOCK(d);
@@ -917,31 +923,47 @@
  *  Bit 3: Reserved bit violation
  *  Bit 4: Instruction fetch
  */
+extern unsigned long last_page_fault_from_rip;
+
 asmlinkage int do_page_fault(struct cpu_user_regs *regs)
 {
-    unsigned long addr, fixup;
+    unsigned long addr, fixup, pt_base_mfn, trace_id;
     int rc;
 
+    last_page_fault_from_rip = regs->rip;
+
     ASSERT(!in_irq());
 
     __asm__ __volatile__ ("mov %%cr2,%0" : "=r" (addr) : );
+    __asm__ __volatile__ ("mov %%cr3,%0" : "=r" (pt_base_mfn) : );
+    pt_base_mfn >>= 12;
+    trace_id =
+        ((regs->error_code << 0) & 0xffff) |
+        ((unsigned long)((current && current->domain) ? current->domain->domain_id : DOMID_XEN) << 16) |
+        ((unsigned long)current->vcpu_id << 32);
 
     DEBUGGER_trap_entry(TRAP_page_fault, regs);
 
     perfc_incrc(page_faults);
 
-    if ( unlikely((rc = fixup_page_fault(addr, regs)) != 0) )
+    if ( unlikely((rc = fixup_page_fault(addr, regs)) != 0) ) {
+        TRACE_5D(TRC_EXCEPT_PAGE_FAULT_FIXABLE, trace_id, regs->eip, addr, pt_base_mfn, 0);
         return rc;
+    }
 
     if ( unlikely(!guest_mode(regs)) )
     {
-        if ( spurious_page_fault(addr, regs) )
+        if ( spurious_page_fault(addr, regs) ) {
+            TRACE_5D(TRC_EXCEPT_PAGE_FAULT_SPURIOUS, trace_id, regs->eip, addr, pt_base_mfn, 0);
             return EXCRET_not_a_fault;
+        }
 
         if ( likely((fixup = search_exception_table(regs->eip)) != 0) )
         {
             perfc_incrc(copy_user_faults);
             regs->eip = fixup;
+
+            TRACE_5D(TRC_EXCEPT_PAGE_FAULT_CHECKED, trace_id, regs->eip, addr, pt_base_mfn, fixup);
             return 0;
         }
 
@@ -955,6 +977,7 @@
               smp_processor_id(), regs->error_code, _p(addr));
     }
 
+    TRACE_5D(TRC_EXCEPT_PAGE_FAULT_PROPAGATE, trace_id, regs->eip, addr, pt_base_mfn, 0);
     propagate_page_fault(addr, regs->error_code);
     return 0;
 }
diff -r ea04335d238b xen/arch/x86/x86_64/entry.S
--- a/xen/arch/x86/x86_64/entry.S	Thu Aug  3 18:45:14 2006
+++ b/xen/arch/x86/x86_64/entry.S	Wed Aug 16 04:26:29 2006
@@ -337,6 +337,14 @@
         jnz   test_all_events
         jmp   restore_all_xen
 
+.data
+ENTRY(last_exception_type)
+  .int 0
+
+ENTRY(last_exception_error_code)
+  .int 0
+.previous
+
         ALIGN
 /* No special register assumptions. */
 handle_exception:
@@ -345,7 +353,12 @@
         jz    exception_with_ints_disabled
         sti
         movq  %rsp,%rdi
+        movl  UREGS_error_code(%rsp),%eax
+        leaq  last_exception_error_code(%rip),%rdx
+        movl  %eax,(%rdx)
         movl  UREGS_entry_vector(%rsp),%eax
+        leaq  last_exception_type(%rip),%rdx
+        movl  %eax,(%rdx)
         leaq  exception_table(%rip),%rdx
         GET_CURRENT(%rbx)
         PERFC_INCR(PERFC_exceptions, %rax)
diff -r ea04335d238b xen/arch/x86/x86_64/traps.c
--- a/xen/arch/x86/x86_64/traps.c	Thu Aug  3 18:45:14 2006
+++ b/xen/arch/x86/x86_64/traps.c	Wed Aug 16 04:26:29 2006
@@ -21,6 +21,18 @@
 
 #include <public/callback.h>
 
+#define TRAP_COUNT 20
+static char *trap_name[TRAP_COUNT] = { 
+    "divide error", "debug", "nmi", "bkpt",
+    "overflow", "bounds", "invalid opcode", "device not available",
+    "double fault",  "coprocessor segment", "invalid tss", "segment not found", 
+    "stack error", "general protection fault", "page fault", "spurious interrupt",
+    "coprocessor error", "alignment check", "machine check", "simd error"
+};
+
+extern unsigned int last_exception_type;
+extern unsigned int last_exception_error_code;
+
 void show_registers(struct cpu_user_regs *regs)
 {
     struct cpu_user_regs fault_regs = *regs;
@@ -47,6 +59,8 @@
     printk("----[ Xen-%d.%d%s    %s ]----\n",
            xen_major_version(), xen_minor_version(), xen_extra_version(),
            print_tainted(taint_str));
+    printk("Trap: %s (%d)\n", (last_exception_type < TRAP_COUNT) ? trap_name[last_exception_type] : "Unknown", last_exception_type);
+    printk("Error code %08x\n", last_exception_error_code);
     printk("CPU:    %d\nRIP:    %04x:[<%016lx>]",
            smp_processor_id(), fault_regs.cs, fault_regs.rip);
     if ( !guest_mode(regs) )
diff -r ea04335d238b xen/common/event_channel.c
--- a/xen/common/event_channel.c	Thu Aug  3 18:45:14 2006
+++ b/xen/common/event_channel.c	Wed Aug 16 04:26:29 2006
@@ -24,11 +24,14 @@
 #include <xen/irq.h>
 #include <xen/iocap.h>
 #include <xen/guest_access.h>
+#include <xen/trace.h>
 #include <asm/current.h>
 
 #include <public/xen.h>
 #include <public/event_channel.h>
 #include <acm/acm_hooks.h>
+
+#define ENABLE_EVENT_DEBUG
 
 #define bucket_from_port(d,p) \
     ((d)->evtchn[(p)/EVTCHNS_PER_BUCKET])
@@ -442,11 +445,14 @@
     struct evtchn *lchn, *rchn;
     struct domain *ld = current->domain, *rd;
     int            rport, ret = 0;
+    struct vcpu *vt;
 
     spin_lock(&ld->evtchn_lock);
 
     if ( unlikely(!port_is_valid(ld, lport)) )
     {
+        TRACE_5D(TRC_EVTCHN_SEND, 0,
+                 ((current->domain->domain_id << 16) | current->vcpu_id), lport, 0, 0);
         spin_unlock(&ld->evtchn_lock);
         return -EINVAL;
     }
@@ -458,15 +464,31 @@
         rd    = lchn->u.interdomain.remote_dom;
         rport = lchn->u.interdomain.remote_port;
         rchn  = evtchn_from_port(rd, rport);
+        vt = rd->vcpu[rchn->notify_vcpu_id];
+
+        TRACE_5D(TRC_EVTCHN_SEND, 1,
+                 ((current->domain->domain_id << 16) | current->vcpu_id), lport,
+                 ((rd->domain_id << 16) | vt->vcpu_id), rport);
+
         evtchn_set_pending(rd->vcpu[rchn->notify_vcpu_id], rport);
         break;
     case ECS_IPI:
+        TRACE_5D(TRC_EVTCHN_SEND, 2,
+                 ((current->domain->domain_id << 16) | current->vcpu_id), lport,
+                 ((ld->domain_id << 16) | ld->vcpu[lchn->notify_vcpu_id]->vcpu_id), lport);
+
         evtchn_set_pending(ld->vcpu[lchn->notify_vcpu_id], lport);
         break;
     case ECS_UNBOUND:
+        TRACE_5D(TRC_EVTCHN_SEND, 3,
+                 ((current->domain->domain_id << 16) | current->vcpu_id), lport,
+                 0, 0);
         /* silently drop the notification */
         break;
     default:
+        TRACE_5D(TRC_EVTCHN_SEND, 4,
+                 ((current->domain->domain_id << 16) | current->vcpu_id), lport,
+                 0, 0);
         ret = -EINVAL;
     }
 
@@ -474,7 +496,6 @@
 
     return ret;
 }
-
 
 void evtchn_set_pending(struct vcpu *v, int port)
 {
@@ -488,24 +509,42 @@
      * others may require explicit memory barriers.
      */
 
-    if ( test_and_set_bit(port, s->evtchn_pending) )
-        return;
+    int action_taken = 0;
+
+    if ( test_and_set_bit(port, s->evtchn_pending) ) {
+        action_taken = 1;
+        goto out;
+    }
 
     if ( !test_bit        (port, s->evtchn_mask) &&
          !test_and_set_bit(port / BITS_PER_LONG,
                            &v->vcpu_info->evtchn_pending_sel) )
     {
+        action_taken = 2;
         vcpu_mark_events_pending(v);
-    }
-    
+    } else {
+        action_taken = 3;
+    }
+
     /* Check if some VCPU might be polling for this event. */
     if ( unlikely(test_bit(_DOMF_polling, &d->domain_flags)) &&
          likely(test_and_clear_bit(_DOMF_polling, &d->domain_flags)) )
     {
         for_each_vcpu ( d, v )
-            if ( test_and_clear_bit(_VCPUF_polling, &v->vcpu_flags) )
+            if ( test_and_clear_bit(_VCPUF_polling, &v->vcpu_flags) ) {
+                action_taken |= 0x10;
                 vcpu_unblock(v);
-    }
+            }
+    }
+
+  out:
+    TRACE_5D(TRC_EVTCHN_SET_PENDING, d->domain_id, v->vcpu_id, port, 
+             (test_bit(port, s->evtchn_mask) & 1 << 0) |
+             ((test_bit(port, s->evtchn_pending) & 1) << 4) |
+             ((v->vcpu_info->evtchn_upcall_mask & 1) << 8) | 
+             ((v->vcpu_info->evtchn_upcall_pending & 1) << 12) |
+             (test_bit(port / BITS_PER_LONG, &v->vcpu_info->evtchn_pending_sel) << 16),
+             action_taken);
 }
 
 
@@ -516,8 +555,12 @@
     ASSERT(!virq_is_global(virq));
 
     port = v->virq_to_evtchn[virq];
-    if ( unlikely(port == 0) )
+    if ( unlikely(port == 0) ) {
+        TRACE_5D(TRC_EVTCHN_SEND_VCPU_VIRQ, v->domain->domain_id, v->vcpu_id, virq, port, 0);
         return;
+    }
+
+    TRACE_5D(TRC_EVTCHN_SEND_VCPU_VIRQ, v->domain->domain_id, v->vcpu_id, virq, port, 1);
 
     evtchn_set_pending(v, port);
 }
@@ -535,10 +578,13 @@
         return;
 
     port = v->virq_to_evtchn[virq];
-    if ( unlikely(port == 0) )
+    if ( unlikely(port == 0) ) {
+        TRACE_5D(TRC_EVTCHN_SEND_GLOBAL_VIRQ, d->domain_id, d->vcpu[0]->vcpu_id, virq, port, 0);
         return;
+    }
 
     chn = evtchn_from_port(d, port);
+    TRACE_5D(TRC_EVTCHN_SEND_GLOBAL_VIRQ, d->domain_id, d->vcpu[0]->vcpu_id, virq, port, 1);
     evtchn_set_pending(d->vcpu[chn->notify_vcpu_id], port);
 }
 
@@ -668,6 +714,7 @@
     shared_info_t *s = d->shared_info;
     int            port = unmask->port;
     struct vcpu   *v;
+    int action_taken = 0;
 
     spin_lock(&d->evtchn_lock);
 
@@ -689,7 +736,16 @@
                             &v->vcpu_info->evtchn_pending_sel) )
     {
         vcpu_mark_events_pending(v);
-    }
+        action_taken = 1;
+    }
+
+    TRACE_5D(TRC_EVTCHN_UNMASK, d->domain_id, v->vcpu_id, port, 
+             (test_bit(port, s->evtchn_mask) << 0) |
+             (test_bit(port, s->evtchn_pending) << 4) |
+             ((v->vcpu_info->evtchn_upcall_mask & 1) << 12) | 
+             ((v->vcpu_info->evtchn_upcall_pending & 1) << 16) |
+             (test_bit(port / BITS_PER_LONG, &v->vcpu_info->evtchn_pending_sel) << 20),
+             action_taken);
 
     spin_unlock(&d->evtchn_lock);
 
diff -r ea04335d238b xen/common/grant_table.c
--- a/xen/common/grant_table.c	Thu Aug  3 18:45:14 2006
+++ b/xen/common/grant_table.c	Wed Aug 16 04:26:29 2006
@@ -261,8 +261,6 @@
         }
     }
 
-    TRACE_1D(TRC_MEM_PAGE_GRANT_MAP, op->dom);
-
     ld->grant_table->maptrack[handle].domid = op->dom;
     ld->grant_table->maptrack[handle].ref   = op->ref;
     ld->grant_table->maptrack[handle].flags = op->flags;
@@ -270,6 +268,13 @@
     op->dev_bus_addr = (u64)frame << PAGE_SHIFT;
     op->handle       = handle;
     op->status       = GNTST_okay;
+
+    TRACE_5D(TRC_MEM_PAGE_GRANT_MAP,
+             ((uint64_t)(op->flags & 0xffff) << 48) | ((uint64_t)(op->status & 0xffff) << 32) | ((uint64_t)op->dom << 16) | ((uint64_t)current->domain->domain_id),
+             op->dev_bus_addr,
+             op->host_addr,
+             handle,
+             op->ref);
 
     put_domain(rd);
     return;
@@ -357,8 +362,6 @@
         op->status = GNTST_bad_domain;
         return;
     }
-
-    TRACE_1D(TRC_MEM_PAGE_GRANT_UNMAP, dom);
 
     act = &rd->grant_table->active[ref];
     sha = &rd->grant_table->shared[ref];
@@ -429,6 +432,13 @@
         gnttab_clear_flag(_GTF_reading, &sha->flags);
 
  unmap_out:
+    TRACE_5D(TRC_MEM_PAGE_GRANT_UNMAP,
+             ((uint64_t)(flags & 0xffff) << 48) | ((uint64_t)(rc & 0xffff) << 32) | ((uint64_t)dom << 16) | ((uint64_t)current->domain->domain_id),
+             op->dev_bus_addr,
+             op->host_addr,
+             op->handle,
+             ref);
+
     op->status = rc;
     spin_unlock(&rd->grant_table->lock);
     put_domain(rd);
@@ -680,7 +690,6 @@
 
         spin_unlock(&e->page_alloc_lock);
 
-        TRACE_1D(TRC_MEM_PAGE_GRANT_TRANSFER, e->domain_id);
 
         /* Tell the guest about its new page frame. */
         sha = &e->grant_table->shared[gop.ref];
@@ -692,6 +701,13 @@
         put_domain(e);
 
         gop.status = GNTST_okay;
+
+        TRACE_5D(TRC_MEM_PAGE_GRANT_TRANSFER,
+                 ((uint64_t)(gop.status & 0xffff) << 32) | ((uint64_t)gop.domid << 16) | ((uint64_t)current->domain->domain_id),
+                 gop.mfn << 12,
+                 0,
+                 0,
+                 gop.ref);
 
     copyback:
         if ( unlikely(__copy_to_guest_offset(uop, i, &gop, 1)) )
diff -r ea04335d238b xen/drivers/char/console.c
--- a/xen/drivers/char/console.c	Thu Aug  3 18:45:14 2006
+++ b/xen/drivers/char/console.c	Wed Aug 16 04:26:29 2006
@@ -41,7 +41,7 @@
 boolean_param("sync_console", opt_sync_console);
 
 static int xpos, ypos;
-static unsigned char *video;
+unsigned char *video;
 
 #define CONRING_SIZE 16384
 #define CONRING_IDX_MASK(i) ((i)&(CONRING_SIZE-1))
diff -r ea04335d238b xen/include/asm-x86/domain.h
--- a/xen/include/asm-x86/domain.h	Thu Aug  3 18:45:14 2006
+++ b/xen/include/asm-x86/domain.h	Wed Aug 16 04:26:29 2006
@@ -112,6 +112,9 @@
 
     /* Shadow-translated guest: Pseudophys base address of reserved area. */
     unsigned long first_reserved_pfn;
+
+    /* PTLsim specific */
+    l4_pgentry_t* pt_overlay;
 } __cacheline_aligned;
 
 #ifdef CONFIG_X86_PAE
diff -r ea04335d238b xen/include/asm-x86/mm.h
--- a/xen/include/asm-x86/mm.h	Thu Aug  3 18:45:14 2006
+++ b/xen/include/asm-x86/mm.h	Wed Aug 16 04:26:29 2006
@@ -7,6 +7,7 @@
 #include <xen/list.h>
 #include <asm/io.h>
 #include <asm/uaccess.h>
+#include <asm/current.h>
 
 /*
  * Per-page-frame information.
@@ -382,7 +383,11 @@
 
 #endif
 
-int new_guest_cr3(unsigned long pfn);
+int update_vcpu_pt_base(struct vcpu *v, unsigned long mfn, int update_cr3);
+
+static inline int new_guest_cr3(unsigned long mfn) {
+  return update_vcpu_pt_base(current, mfn, 1);
+}
 
 void propagate_page_fault(unsigned long addr, u16 error_code);
 
diff -r ea04335d238b xen/include/public/dom0_ops.h
--- a/xen/include/public/dom0_ops.h	Thu Aug  3 18:45:14 2006
+++ b/xen/include/public/dom0_ops.h	Wed Aug 16 04:26:29 2006
@@ -539,6 +539,13 @@
 };
 typedef struct dom0_settimeoffset dom0_settimeoffset_t;
 DEFINE_XEN_GUEST_HANDLE(dom0_settimeoffset_t);
+
+#define DOM0_SET_LOCKUP_DEBUG    51
+struct dom0_set_lockup_debug {
+    unsigned int enable;
+};
+typedef struct dom0_set_lockup_debug dom0_set_lockup_debug_t;
+DEFINE_XEN_GUEST_HANDLE(dom0_set_lockup_debug_t);
 
 struct dom0_op {
     uint32_t cmd;
@@ -583,6 +590,7 @@
         struct dom0_hypercall_init    hypercall_init;
         struct dom0_domain_setup      domain_setup;
         struct dom0_settimeoffset     settimeoffset;
+        struct dom0_set_lockup_debug  lockupdebug;
         uint8_t                       pad[128];
     } u;
 };
diff -r ea04335d238b xen/include/public/trace.h
--- a/xen/include/public/trace.h	Thu Aug  3 18:45:14 2006
+++ b/xen/include/public/trace.h	Wed Aug 16 04:26:29 2006
@@ -15,6 +15,8 @@
 #define TRC_DOM0OP  0x0004f000    /* Xen DOM0 operation trace */
 #define TRC_VMX     0x0008f000    /* Xen VMX trace            */
 #define TRC_MEM     0x000af000    /* Xen memory trace         */
+#define TRC_EVTCHN  0x0010f000    /* Event channel operations */
+#define TRC_EXCEPT  0x0020f000    /* Exceptions               */
 #define TRC_ALL     0xfffff000
 
 /* Trace subclasses */
@@ -56,6 +58,17 @@
 
 #define TRC_VMX_INT             (TRC_VMXINT + 1)
 
+#define TRC_EVTCHN_SEND                (TRC_EVTCHN + 1)
+#define TRC_EVTCHN_SET_PENDING         (TRC_EVTCHN + 2)
+#define TRC_EVTCHN_UNMASK              (TRC_EVTCHN + 3)
+#define TRC_EVTCHN_SEND_VCPU_VIRQ      (TRC_EVTCHN + 4)
+#define TRC_EVTCHN_SEND_GLOBAL_VIRQ    (TRC_EVTCHN + 5)
+#define TRC_EVTCHN_SEND_PIRQ           (TRC_EVTCHN + 6)
+
+#define TRC_EXCEPT_PAGE_FAULT_FIXABLE   (TRC_EXCEPT + 0)
+#define TRC_EXCEPT_PAGE_FAULT_SPURIOUS  (TRC_EXCEPT + 1)
+#define TRC_EXCEPT_PAGE_FAULT_CHECKED   (TRC_EXCEPT + 2)
+#define TRC_EXCEPT_PAGE_FAULT_PROPAGATE (TRC_EXCEPT + 3)
 
 /* This structure represents a single trace buffer record. */
 struct t_rec {
diff -r ea04335d238b xen/include/public/vcpu.h
--- a/xen/include/public/vcpu.h	Thu Aug  3 18:45:14 2006
+++ b/xen/include/public/vcpu.h	Wed Aug 16 04:26:29 2006
@@ -108,6 +108,9 @@
 };
 typedef struct vcpu_register_runstate_memory_area vcpu_register_runstate_memory_area_t;
 
+/* PTLsim specific */
+#define VCPUOP_get_registered_runstate_memory_area 6
+
 #endif /* __XEN_PUBLIC_VCPU_H__ */
 
 /*
diff -r ea04335d238b xen/include/public/xen.h
--- a/xen/include/public/xen.h	Thu Aug  3 18:45:14 2006
+++ b/xen/include/public/xen.h	Wed Aug 16 04:26:29 2006
@@ -195,20 +195,58 @@
 #define MMUEXT_SET_LDT          13
 #define MMUEXT_NEW_USER_BASEPTR 15
 
+/* PTLsim specific calls */
+#define MMUEXT_GET_GDT_TEMPLATE     32
+#define MMUEXT_GET_KERNEL_BASEPTR   33
+#define MMUEXT_SET_KERNEL_BASEPTR   34
+#define MMUEXT_GET_USER_BASEPTR     35
+#define MMUEXT_SET_USER_BASEPTR     36
+#define MMUEXT_QUERY_PAGES          37
+#define MMUEXT_SET_PT_OVERLAY       38
+
 #ifndef __ASSEMBLY__
+
+union page_type {
+    struct {
+        /* Use 0xffffffffffffffffULL for end of list marker */
+        uint64_t mfn;
+    } in;
+    struct {
+        uint8_t type;
+        uint8_t pinned:1;
+        uint16_t type_count;
+        uint32_t total_count;
+    } out;
+};
+
+typedef union page_type page_type_t;
+
+#define PAGE_TYPE_NONE           0 /* no special uses of this page */
+#define PAGE_TYPE_L1             1 /* using this page as an L1 page table? */
+#define PAGE_TYPE_L2             2 /* using this page as an L2 page table? */
+#define PAGE_TYPE_L3             3 /* using this page as an L3 page table? */
+#define PAGE_TYPE_L4             4 /* using this page as an L4 page table? */
+#define PAGE_TYPE_GDT            5 /* using this page in a GDT? */
+#define PAGE_TYPE_LDT            6 /* using this page in an LDT? */
+#define PAGE_TYPE_WRITABLE       7 /* has writable mappings of this page? */
+#define PAGE_TYPE_INVALID_MFN  254 /* MFN is invalid */
+#define PAGE_TYPE_INACCESSIBLE 255 /* not accessible to this domain */
+
 struct mmuext_op {
     unsigned int cmd;
     union {
         /* [UN]PIN_TABLE, NEW_BASEPTR, NEW_USER_BASEPTR */
         xen_pfn_t     mfn;
-        /* INVLPG_LOCAL, INVLPG_ALL, SET_LDT */
+        /* INVLPG_LOCAL, INVLPG_ALL, SET_LDT, GET_GDT_TEMPLATE, QUERY_PAGES, SET_PT_OVERLAY */
         unsigned long linear_addr;
     } arg1;
     union {
-        /* SET_LDT */
+        /* SET_LDT, QUERY_PAGES */
         unsigned int nr_ents;
         /* TLB_FLUSH_MULTI, INVLPG_MULTI */
         void *vcpumask;
+        /* NEW_BASEPTR_EXT, NEW_USER_BASEPTR_EXT */
+        unsigned int vcpuid;
     } arg2;
 };
 typedef struct mmuext_op mmuext_op_t;
