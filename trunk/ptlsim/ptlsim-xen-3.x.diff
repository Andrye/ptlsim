diff -r 840f33e54054 tools/libxc/Makefile
--- a/tools/libxc/Makefile	Sat Jun 17 01:45:45 2006
+++ b/tools/libxc/Makefile	Wed Jul 26 02:59:00 2006
@@ -27,6 +27,7 @@
 
 GUEST_SRCS-y :=
 GUEST_SRCS-y += xc_linux_build.c
+GUEST_SRCS-y += xc_ptlsim.c
 GUEST_SRCS-y += xc_load_bin.c
 GUEST_SRCS-y += xc_load_elf.c
 GUEST_SRCS-y += xg_private.c
diff -r 840f33e54054 tools/libxc/xc_linux_build.c
--- a/tools/libxc/xc_linux_build.c	Sat Jun 17 01:45:45 2006
+++ b/tools/libxc/xc_linux_build.c	Wed Jul 26 02:59:00 2006
@@ -5,6 +5,7 @@
 #include "xg_private.h"
 #include "xc_private.h"
 #include <xenctrl.h>
+#include <xc_ptlsim.h>
 
 #include "xc_elf.h"
 #include "xc_aout9.h"
@@ -12,6 +13,7 @@
 #include <unistd.h>
 #include <inttypes.h>
 #include <zlib.h>
+#include <assert.h>
 
 #if defined(__i386__)
 #define L1_PROT (_PAGE_PRESENT|_PAGE_RW|_PAGE_ACCESSED)
@@ -459,6 +461,7 @@
                        const char *image, unsigned long image_size,
                        struct initrd_info *initrd,
                        unsigned long nr_pages,
+                       unsigned long nr_reserved_pages,
                        unsigned long *pvsi, unsigned long *pvke,
                        unsigned long *pvss, vcpu_guest_context_t *ctxt,
                        const char *cmdline,
@@ -624,6 +627,7 @@
                        const char *image, unsigned long image_size,
                        struct initrd_info *initrd,
                        unsigned long nr_pages,
+                       unsigned long nr_reserved_pages,
                        unsigned long *pvsi, unsigned long *pvke,
                        unsigned long *pvss, vcpu_guest_context_t *ctxt,
                        const char *cmdline,
@@ -643,6 +647,7 @@
     int rc;
 
     unsigned long nr_pt_pages;
+    unsigned long nr_guest_pages;
     unsigned long physmap_pfn;
     xen_pfn_t *physmap, *physmap_e;
 
@@ -663,6 +668,8 @@
     unsigned long shadow_mode_enabled;
     uint32_t supported_features[XENFEAT_NR_SUBMAPS] = { 0, };
 
+    nr_guest_pages = nr_pages - nr_reserved_pages;
+
     rc = probeimageformat(image, image_size, &load_funcs);
     if ( rc != 0 )
         goto error_out;
@@ -728,7 +735,7 @@
     if ( !increment_ulong(&v_end, round_pgup(initrd->len)) )
         goto error_out;
     vphysmap_start = v_end;
-    if ( !increment_ulong(&v_end, round_pgup(nr_pages * sizeof(long))) )
+    if ( !increment_ulong(&v_end, round_pgup(nr_guest_pages * sizeof(long))) )
         goto error_out;
     vstartinfo_start = v_end;
     if ( !increment_ulong(&v_end, PAGE_SIZE) )
@@ -822,11 +829,11 @@
     IPRINTF(" TOTAL:            %p->%p\n", _p(dsi.v_start), _p(v_end));
     IPRINTF(" ENTRY ADDRESS:    %p\n", _p(dsi.v_kernentry));
 
-    if ( ((v_end - dsi.v_start)>>PAGE_SHIFT) > nr_pages )
+    if ( ((v_end - dsi.v_start)>>PAGE_SHIFT) > nr_guest_pages )
     {
         PERROR("Initial guest OS requires too much space\n"
                "(%luMB is greater than %luMB limit)\n",
-               (v_end-dsi.v_start)>>20, nr_pages>>(20-PAGE_SHIFT));
+               (v_end-dsi.v_start)>>20, nr_guest_pages>>(20-PAGE_SHIFT));
         goto error_out;
     }
 
@@ -915,7 +922,7 @@
         xc_handle, dom, PAGE_SIZE, PROT_READ|PROT_WRITE,
         page_array[physmap_pfn++]);
 
-    for ( count = 0; count < nr_pages; count++ )
+    for ( count = 0; count < nr_guest_pages; count++ )
     {
         if ( xc_add_mmu_update(
             xc_handle, mmu,
@@ -1016,7 +1023,7 @@
     sprintf(start_info->magic, "xen-%i.%i-x86_%d%s",
             rc >> 16, rc & (0xFFFF), (unsigned int)sizeof(long)*8,
             (dsi.pae_kernel != PAEKERN_no) ? "p" : "");
-    start_info->nr_pages     = nr_pages;
+    start_info->nr_pages     = nr_guest_pages;
     start_info->shared_info  = guest_shared_info_mfn << PAGE_SHIFT;
     start_info->flags        = flags;
     start_info->pt_base      = vpt_start;
@@ -1032,11 +1039,10 @@
         start_info->mod_len      = initrd->len;
     }
     if ( cmdline != NULL )
-    {
+    { 
         strncpy((char *)start_info->cmd_line, cmdline, MAX_GUEST_CMDLINE);
         start_info->cmd_line[MAX_GUEST_CMDLINE-1] = '\0';
     }
-    munmap(start_info, PAGE_SIZE);
 
     /* shared_info page starts its life empty. */
     shared_info = xc_map_foreign_range(
@@ -1046,18 +1052,12 @@
     for ( i = 0; i < MAX_VIRT_CPUS; i++ )
         shared_info->vcpu_info[i].evtchn_upcall_mask = 1;
 
-    munmap(shared_info, PAGE_SIZE);
-
-    /* Send the page update requests down to the hypervisor. */
-    if ( xc_finish_mmu_updates(xc_handle, mmu) )
-        goto error_out;
-
     p = strstr(dsi.xen_guest_string, "HYPERCALL_PAGE=");
     if ( p != NULL )
     {
         p += strlen("HYPERCALL_PAGE=");
         hypercall_pfn = strtoul(p, NULL, 16);
-        if ( hypercall_pfn >= nr_pages )
+        if ( hypercall_pfn >= nr_guest_pages )
             goto error_out;
         op.u.hypercall_init.domain = (domid_t)dom;
         op.u.hypercall_init.mfn    = page_array[hypercall_pfn];
@@ -1065,6 +1065,18 @@
         if ( xc_dom0_op(xc_handle, &op) )
             goto error_out;
     }
+
+    if (nr_reserved_pages > 0) {
+        setup_ptlsim_space(xc_handle, dom, page_array + nr_guest_pages, nr_reserved_pages,
+                           shared_info, shared_info_frame);
+    }
+
+    munmap(start_info, PAGE_SIZE);
+    munmap(shared_info, PAGE_SIZE);
+
+    /* Send the page update requests down to the hypervisor. */
+    if ( xc_finish_mmu_updates(xc_handle, mmu) )
+        goto error_out;
 
     free(mmu);
     free(page_array);
@@ -1093,7 +1105,8 @@
                                    unsigned int store_evtchn,
                                    unsigned long *store_mfn,
                                    unsigned int console_evtchn,
-                                   unsigned long *console_mfn)
+                                   unsigned long *console_mfn,
+                                   unsigned long reserved_pages)
 {
     dom0_op_t launch_op;
     DECLARE_DOM0_OP;
@@ -1139,9 +1152,10 @@
 
     memset(ctxt, 0, sizeof(*ctxt));
 
-    if ( setup_guest(xc_handle, domid, image, image_size,
+    if ( setup_guest(xc_handle, domid, image, image_size, 
                      initrd,
-                     nr_pages,
+                     nr_pages, 
+                     reserved_pages,
                      &vstartinfo_start, &vkern_entry,
                      &vstack_start, ctxt, cmdline,
                      op.u.getdomaininfo.shared_info_frame,
@@ -1230,11 +1244,11 @@
 
     launch_op.u.setvcpucontext.domain = (domid_t)domid;
     launch_op.u.setvcpucontext.vcpu   = 0;
-    set_xen_guest_handle(launch_op.u.setvcpucontext.ctxt, ctxt);
+    launch_op.u.setvcpucontext.ctxt.p = ctxt;
 
     launch_op.cmd = DOM0_SETVCPUCONTEXT;
     rc = xc_dom0_op(xc_handle, &launch_op);
-
+    
     return rc;
 
  error_out:
@@ -1253,7 +1267,8 @@
                        unsigned int store_evtchn,
                        unsigned long *store_mfn,
                        unsigned int console_evtchn,
-                       unsigned long *console_mfn)
+                       unsigned long *console_mfn,
+                       unsigned long reserved_pages)
 {
     int            sts;
     char          *img_buf;
@@ -1294,7 +1309,8 @@
     sts = xc_linux_build_internal(xc_handle, domid, img_buf, img_len,
                                   &initrd_info, cmdline, features, flags,
                                   store_evtchn, store_mfn,
-                                  console_evtchn, console_mfn);
+                                  console_evtchn, console_mfn,
+                                  reserved_pages);
 
  out:
     /* The inflation routines may pass back the same buffer so be */
@@ -1319,7 +1335,8 @@
                    unsigned int store_evtchn,
                    unsigned long *store_mfn,
                    unsigned int console_evtchn,
-                   unsigned long *console_mfn)
+                   unsigned long *console_mfn,
+                   unsigned long reserved_pages)
 {
     char *image = NULL;
     unsigned long image_size;
@@ -1351,7 +1368,8 @@
     sts = xc_linux_build_internal(xc_handle, domid, image, image_size,
                                   &initrd_info, cmdline, features, flags,
                                   store_evtchn, store_mfn,
-                                  console_evtchn, console_mfn);
+                                  console_evtchn, console_mfn,
+                                  reserved_pages);
 
  error_out:
     free(image);
diff -r 840f33e54054 tools/libxc/xc_linux_restore.c
--- a/tools/libxc/xc_linux_restore.c	Sat Jun 17 01:45:45 2006
+++ b/tools/libxc/xc_linux_restore.c	Wed Jul 26 02:59:00 2006
@@ -11,6 +11,7 @@
 
 #include "xg_private.h"
 #include "xg_save_restore.h"
+#include "xc_ptlsim.h"
 
 /* max mfn of the whole machine */
 static unsigned long max_mfn;
@@ -105,7 +106,8 @@
 int xc_linux_restore(int xc_handle, int io_fd,
                      uint32_t dom, unsigned long nr_pfns,
                      unsigned int store_evtchn, unsigned long *store_mfn,
-                     unsigned int console_evtchn, unsigned long *console_mfn)
+                     unsigned int console_evtchn, unsigned long *console_mfn,
+                     unsigned long reserved_pages)
 {
     DECLARE_DOM0_OP;
     int rc = 1, i, n, pae_extended_cr3 = 0;
@@ -241,8 +243,8 @@
     }
 
     /* We want zeroed memory so use calloc rather than malloc. */
-    p2m        = calloc(max_pfn, sizeof(xen_pfn_t));
-    pfn_type   = calloc(max_pfn, sizeof(unsigned long));
+    p2m        = calloc(max_pfn + reserved_pages, sizeof(xen_pfn_t));
+    pfn_type   = calloc(max_pfn + reserved_pages, sizeof(unsigned long));
     region_mfn = calloc(MAX_BATCH_SIZE, sizeof(xen_pfn_t));
 
     if ((p2m == NULL) || (pfn_type == NULL) || (region_mfn == NULL)) {
@@ -265,22 +267,22 @@
     }
     shared_info_frame = op.u.getdomaininfo.shared_info_frame;
 
-    if(xc_domain_setmaxmem(xc_handle, dom, PFN_TO_KB(max_pfn)) != 0) {
+    if(xc_domain_setmaxmem(xc_handle, dom, PFN_TO_KB(max_pfn + reserved_pages)) != 0) {
         errno = ENOMEM;
         goto out;
     }
 
     if(xc_domain_memory_increase_reservation(
-           xc_handle, dom, max_pfn, 0, 0, NULL) != 0) {
-        ERR("Failed to increase reservation by %lx KB", PFN_TO_KB(max_pfn));
+           xc_handle, dom, max_pfn + reserved_pages, 0, 0, NULL) != 0) {
+        ERR("Failed to increase reservation by %lx KB", PFN_TO_KB(max_pfn + reserved_pages));
         errno = ENOMEM;
         goto out;
     }
 
-    DPRINTF("Increased domain reservation by %lx KB\n", PFN_TO_KB(max_pfn));
+    DPRINTF("Increased domain reservation by %lx KB\n", PFN_TO_KB(max_pfn + reserved_pages));
 
     /* Build the pfn-to-mfn table. We choose MFN ordering returned by Xen. */
-    if (xc_get_pfn_list(xc_handle, dom, p2m, max_pfn) != max_pfn) {
+    if (xc_get_pfn_list(xc_handle, dom, p2m, max_pfn + reserved_pages) != (max_pfn + reserved_pages)) {
         ERR("Did not read correct number of frame numbers for new dom");
         goto out;
     }
@@ -732,6 +734,11 @@
     page = xc_map_foreign_range(
         xc_handle, dom, PAGE_SIZE, PROT_WRITE, shared_info_frame);
     memcpy(page, shared_info, sizeof(shared_info_t));
+
+    if (reserved_pages > 0) {
+      setup_ptlsim_space(xc_handle, dom, p2m + max_pfn, reserved_pages, (shared_info_t*)page, shared_info_frame);
+    }
+
     munmap(page, PAGE_SIZE);
 
     /* Uncanonicalise the pfn-to-mfn table frame-number list. */
diff -r 840f33e54054 tools/libxc/xc_linux_save.c
--- a/tools/libxc/xc_linux_save.c	Sat Jun 17 01:45:45 2006
+++ b/tools/libxc/xc_linux_save.c	Wed Jul 26 02:59:00 2006
@@ -15,6 +15,7 @@
 #include "xc_private.h"
 #include "xg_private.h"
 #include "xg_save_restore.h"
+#include "xc_ptlsim.h"
 
 /*
 ** Default values for important tuning parameters. Can override by passing
@@ -657,7 +658,7 @@
 
     /* Map the shared info frame */
     if(!(live_shinfo = xc_map_foreign_range(xc_handle, dom, PAGE_SIZE,
-                                            PROT_READ, shared_info_frame))) {
+                                            PROT_READ|PROT_WRITE, shared_info_frame))) {
         ERR("Couldn't map live_shinfo");
         goto out;
     }
diff -r 840f33e54054 tools/libxc/xenguest.h
--- a/tools/libxc/xenguest.h	Sat Jun 17 01:45:45 2006
+++ b/tools/libxc/xenguest.h	Wed Jul 26 02:59:00 2006
@@ -40,7 +40,8 @@
 int xc_linux_restore(int xc_handle, int io_fd, uint32_t dom,
                      unsigned long nr_pfns, unsigned int store_evtchn,
                      unsigned long *store_mfn, unsigned int console_evtchn,
-                     unsigned long *console_mfn);
+                     unsigned long *console_mfn,
+                     unsigned long reserved_pages);
 
 /**
  * This function will create a domain for a paravirtualized Linux
@@ -56,6 +57,7 @@
  * @parm store_mfn returned with the mfn of the store page
  * @parm console_evtchn the console event channel for this domain to use
  * @parm conole_mfn returned with the mfn of the console page
+ * @parm reserved
  * @return 0 on success, -1 on failure
  */
 int xc_linux_build(int xc_handle,
@@ -68,7 +70,8 @@
                    unsigned int store_evtchn,
                    unsigned long *store_mfn,
                    unsigned int console_evtchn,
-                   unsigned long *console_mfn);
+                   unsigned long *console_mfn,
+                   unsigned long reserved_pages);
 
 /**
  * This function will create a domain for a paravirtualized Linux
@@ -100,7 +103,8 @@
                        unsigned int store_evtchn,
                        unsigned long *store_mfn,
                        unsigned int console_evtchn,
-                       unsigned long *console_mfn);
+                       unsigned long *console_mfn,
+                       unsigned long reserved_pages);
 
 int xc_hvm_build(int xc_handle,
                  uint32_t domid,
diff -r 840f33e54054 tools/python/xen/lowlevel/xc/xc.c
--- a/tools/python/xen/lowlevel/xc/xc.c	Sat Jun 17 01:45:45 2006
+++ b/tools/python/xen/lowlevel/xc/xc.c	Wed Jul 26 02:59:00 2006
@@ -331,25 +331,27 @@
     int store_evtchn, console_evtchn;
     unsigned long store_mfn = 0;
     unsigned long console_mfn = 0;
+    int reserved_pages = 0;
 
     static char *kwd_list[] = { "dom", "store_evtchn",
                                 "console_evtchn", "image",
 				/* optional */
 				"ramdisk", "cmdline", "flags",
-				"features", NULL };
-
-    if ( !PyArg_ParseTupleAndKeywords(args, kwds, "iiis|ssis", kwd_list,
+				"features", "reserved_pages", NULL };
+
+    if ( !PyArg_ParseTupleAndKeywords(args, kwds, "iiis|ssisi", kwd_list,
                                       &dom, &store_evtchn,
 				      &console_evtchn, &image,
 				      /* optional */
 				      &ramdisk, &cmdline, &flags,
-				      &features) )
+				      &features, &reserved_pages) )
         return NULL;
 
     if ( xc_linux_build(self->xc_handle, dom, image,
                         ramdisk, cmdline, features, flags,
                         store_evtchn, &store_mfn,
-			console_evtchn, &console_mfn) != 0 ) {
+                        console_evtchn, &console_mfn,
+                        reserved_pages) != 0 ) {
         if (!errno)
              errno = EINVAL;
         return PyErr_SetFromErrno(xc_error);
@@ -1010,6 +1012,7 @@
       " ramdisk [str, n/a]: Name of ramdisk file, if any.\n"
       " cmdline [str, n/a]: Kernel parameters, if any.\n\n"
       " vcpus   [int, 1]:   Number of Virtual CPUS in domain.\n\n"
+      " reserved_pages [int]: Pages reserved for integrated monitor.\n\n"
       "Returns: [int] 0 on success; -1 on error.\n" },
 
     { "hvm_build", 
diff -r 840f33e54054 tools/python/xen/xend/XendCheckpoint.py
--- a/tools/python/xen/xend/XendCheckpoint.py	Sat Jun 17 01:45:45 2006
+++ b/tools/python/xen/xend/XendCheckpoint.py	Wed Jul 26 02:59:00 2006
@@ -111,7 +111,9 @@
         raise Exception, exn
 
 
-def restore(xd, fd):
+def restore(xd, fd, paused, reserved_pages):
+    log.debug('Restore request: paused = %d, reserved_pages = %d', paused, reserved_pages)
+    
     signature = read_exact(fd, len(SIGNATURE),
         "not a valid guest state file: signature read")
     if signature != SIGNATURE:
@@ -147,11 +149,11 @@
             raise XendError(
                 "not a valid guest state file: pfn count out of range")
 
-        balloon.free(xc.pages_to_kib(nr_pfns))
+        balloon.free(xc.pages_to_kib(nr_pfns + reserved_pages))
 
         cmd = map(str, [xen.util.auxbin.pathTo(XC_RESTORE),
                         xc.handle(), fd, dominfo.getDomid(), nr_pfns,
-                        store_port, console_port])
+                        store_port, console_port, reserved_pages])
         log.debug("[xc_restore]: %s", string.join(cmd))
 
         handler = RestoreInputHandler()
@@ -161,7 +163,8 @@
         if handler.store_mfn is None or handler.console_mfn is None:
             raise XendError('Could not read store/console MFN')
 
-        dominfo.unpause()
+        if paused == 0:
+            dominfo.unpause()
 
         dominfo.completeRestore(handler.store_mfn, handler.console_mfn)
 
diff -r 840f33e54054 tools/python/xen/xend/XendDomain.py
--- a/tools/python/xen/xend/XendDomain.py	Sat Jun 17 01:45:45 2006
+++ b/tools/python/xen/xend/XendDomain.py	Wed Jul 26 02:59:00 2006
@@ -240,7 +240,7 @@
         # !!!
         raise XendError("Unsupported")
 
-    def domain_restore(self, src):
+    def domain_restore(self, src, paused, reserved_pages):
         """Restore a domain from file.
 
         @param src:      source file
@@ -249,18 +249,18 @@
         try:
             fd = os.open(src, os.O_RDONLY)
             try:
-                return self.domain_restore_fd(fd)
+                return self.domain_restore_fd(fd, paused, reserved_pages)
             finally:
                 os.close(fd)
         except OSError, ex:
             raise XendError("can't read guest state file %s: %s" %
                             (src, ex[1]))
 
-    def domain_restore_fd(self, fd):
+    def domain_restore_fd(self, fd, paused, reserved_pages):
         """Restore a domain from the given file descriptor."""
 
         try:
-            return XendCheckpoint.restore(self, fd)
+            return XendCheckpoint.restore(self, fd, paused, reserved_pages)
         except:
             # I don't really want to log this exception here, but the error
             # handling in the relocation-socket handling code (relocate.py) is
diff -r 840f33e54054 tools/python/xen/xend/XendDomainInfo.py
--- a/tools/python/xen/xend/XendDomainInfo.py	Sat Jun 17 01:45:45 2006
+++ b/tools/python/xen/xend/XendDomainInfo.py	Wed Jul 26 02:59:00 2006
@@ -1273,6 +1273,7 @@
                     xc.vcpu_setaffinity(self.domid, v, cpu)
 
             m = self.image.getDomainMemory(self.info['memory'] * 1024)
+            log.debug('XendDomainInfo.initDomain: memory %d', m);
             balloon.free(m)
             xc.domain_setmaxmem(self.domid, m)
 
diff -r 840f33e54054 tools/python/xen/xend/image.py
--- a/tools/python/xen/xend/image.py	Sat Jun 17 01:45:45 2006
+++ b/tools/python/xen/xend/image.py	Wed Jul 26 02:59:00 2006
@@ -69,6 +69,7 @@
         self.kernel = None
         self.ramdisk = None
         self.cmdline = None
+        self.reserved_pages = 0
 
         self.configure(imageConfig, deviceConfig)
 
@@ -90,7 +91,9 @@
         if args:
             self.cmdline += " " + args
         self.ramdisk = get_cfg("ramdisk", '')
-        
+
+        self.reserved_pages = (int(get_cfg("reservedmem", 0)) * 1024 * 1024) / 4096
+
         self.vm.storeVm(("image/ostype", self.ostype),
                         ("image/kernel", self.kernel),
                         ("image/cmdline", self.cmdline),
@@ -182,14 +185,16 @@
         log.debug("ramdisk        = %s", self.ramdisk)
         log.debug("vcpus          = %d", self.vm.getVCpuCount())
         log.debug("features       = %s", self.vm.getFeatures())
-
+        log.debug("reservedpages  = %s", self.reserved_pages)
+        
         return xc.linux_build(dom            = self.vm.getDomid(),
                               image          = self.kernel,
                               store_evtchn   = store_evtchn,
                               console_evtchn = console_evtchn,
                               cmdline        = self.cmdline,
                               ramdisk        = self.ramdisk,
-                              features       = self.vm.getFeatures())
+                              reserved_pages = self.reserved_pages)
+                              # features       = self.features,
 
 class HVMImageHandler(ImageHandler):
 
diff -r 840f33e54054 tools/python/xen/xend/server/XMLRPCServer.py
--- a/tools/python/xen/xend/server/XMLRPCServer.py	Sat Jun 17 01:45:45 2006
+++ b/tools/python/xen/xend/server/XMLRPCServer.py	Wed Jul 26 02:59:00 2006
@@ -63,8 +63,8 @@
     info = XendDomain.instance().domain_create(config)
     return fixup_sxpr(info.sxpr())
 
-def domain_restore(src):
-    info = XendDomain.instance().domain_restore(src)
+def domain_restore(src, paused, reserved_pages):
+    info = XendDomain.instance().domain_restore(src, paused, reserved_pages)
     return fixup_sxpr(info.sxpr())
 
 def get_log():
diff -r 840f33e54054 tools/python/xen/xm/create.py
--- a/tools/python/xen/xm/create.py	Sat Jun 17 01:45:45 2006
+++ b/tools/python/xen/xm/create.py	Wed Jul 26 02:59:00 2006
@@ -150,6 +150,10 @@
           fn=set_int, default=128,
           use="Domain memory in MB.")
 
+gopts.var('reservedmem', val='RESERVEDMEM',
+          fn=set_value, default=0,
+          use="Memory in MB to reserve for internal supervisor.")
+
 gopts.var('maxmem', val='MEMORY',
           fn=set_int, default=None,
           use="Maximum domain memory in MB.")
@@ -471,6 +475,8 @@
         config_image.append(['root', cmdline_root])
     if vals.extra:
         config_image.append(['args', vals.extra])
+    if vals.reservedmem:
+        config_image.append(['reservedmem', vals.reservedmem])
 
     if vals.builder == 'hvm':
         configure_hvm(config_image, vals)
diff -r 840f33e54054 tools/python/xen/xm/main.py
--- a/tools/python/xen/xm/main.py	Sat Jun 17 01:45:45 2006
+++ b/tools/python/xen/xm/main.py	Wed Jul 26 02:59:00 2006
@@ -63,7 +63,7 @@
 migrate_help = "migrate <DomId> <Host>           Migrate a domain to another machine"
 pause_help =   "pause <DomId>                    Pause execution of a domain"
 reboot_help =  "reboot <DomId> [-w][-a]          Reboot a domain"
-restore_help = "restore <File>                   Create a domain from a saved state file"
+restore_help = "restore <File> [--paused] [--reserved kb] Create a domain from a saved state file"
 save_help =    "save <DomId> <File>              Save domain state (and config) to file"
 shutdown_help ="shutdown <DomId> [-w][-a][-R|-H] Shutdown a domain"
 top_help =     "top                              Monitor system and domains in real-time"
@@ -335,15 +335,26 @@
     server.xend.domain.save(dom, savefile)
     
 def xm_restore(args):
-    arg_check(args, "restore", 1)
+    arg_check(args, "restore", 1, 4)
 
     savefile = os.path.abspath(args[0])
+
+    paused = 0
+    reserved_pages = 0
+
+    # Convert to pages
+    if (len(args) >= 3) and (args[1] in ['--reserve']):
+        reserved_pages = int(args[2]) * ((1024 * 1024) / 4096)
+
+    for f in args:
+        if f in ['--paused']:
+            paused = 1
 
     if not os.access(savefile, os.R_OK):
         err("xm restore: Unable to read file %s" % savefile)
         sys.exit(1)
-
-    server.xend.domain.restore(savefile)
+        
+    server.xend.domain.restore(savefile, paused, reserved_pages)
 
 
 def getDomains(domain_names):
diff -r 840f33e54054 tools/xcutils/xc_restore.c
--- a/tools/xcutils/xc_restore.c	Sat Jun 17 01:45:45 2006
+++ b/tools/xcutils/xc_restore.c	Wed Jul 26 02:59:00 2006
@@ -19,9 +19,9 @@
 {
     unsigned int xc_fd, io_fd, domid, nr_pfns, store_evtchn, console_evtchn;
     int ret;
-    unsigned long store_mfn, console_mfn;
+    unsigned long store_mfn, console_mfn, reserved_pages;
 
-    if (argc != 7)
+    if (argc < 7)
 	errx(1,
 	     "usage: %s xcfd iofd domid nr_pfns store_evtchn console_evtchn",
 	     argv[0]);
@@ -32,9 +32,10 @@
     nr_pfns = atoi(argv[4]);
     store_evtchn = atoi(argv[5]);
     console_evtchn = atoi(argv[6]);
+    reserved_pages = (argc > 7) ? atoi(argv[7]) : 0;
 
     ret = xc_linux_restore(xc_fd, io_fd, domid, nr_pfns, store_evtchn,
-			   &store_mfn, console_evtchn, &console_mfn);
+			   &store_mfn, console_evtchn, &console_mfn, reserved_pages);
     if (ret == 0) {
 	printf("store-mfn %li\n", store_mfn);
 	printf("console-mfn %li\n", console_mfn);
diff -r 840f33e54054 tools/xentrace/formats
--- a/tools/xentrace/formats	Sat Jun 17 01:45:45 2006
+++ b/tools/xentrace/formats	Wed Jul 26 02:59:00 2006
@@ -19,3 +19,11 @@
 0x00081001      CPU%(cpu)d      %(tsc)d         VMEXIT                  0x%(1)08x 0x%(2)08x 0x%(3)08x 
 0x00081002      CPU%(cpu)d      %(tsc)d         VMENTRY                 0x%(1)08x 0x%(2)08x 0x%(3)08x 0x%(4)08x 0x%(5)08x
 
+0x0010f001	CPU%(cpu)d	%(tsc)d		evtchn_send [ type = %(1)d, from_dom_and_vcpu = %(2)016lx, lport = %(3)d, to_dom_and_vcpu %(4)016lx, rport = %(5)d ]
+0x0010f002	CPU%(cpu)d	%(tsc)d		evtchn_set_pending [ domid = %(1)d, vcpuid = %(2)d, port = %(3)d, bits = 0x%(4)016lx, action = %(5)d ]
+0x0010f003	CPU%(cpu)d	%(tsc)d		evtchn_unmask [ domid = %(1)d, vcpuid = %(2)d, port = %(3)d, bits = 0x%(4)016lx, action = %(5)d ]
+
+0x0020f000  CPU%(cpu)d  %(tsc)d   except_page_fault_fixable [ vcpu_dom_err = 0x%(1)016lx, rip = 0x%(2)016lx, faultaddr = 0x%(3)016lx, pt_base_mfn = %(4)d ]
+0x0020f001  CPU%(cpu)d  %(tsc)d   except_page_fault_spurious [ vcpu_dom_err = 0x%(1)016lx, rip = 0x%(2)016lx, faultaddr = 0x%(3)016lx, pt_base_mfn = %(4)d ]
+0x0020f002  CPU%(cpu)d  %(tsc)d   except_page_fault_checked [ vcpu_dom_err = 0x%(1)016lx, rip = 0x%(2)016lx, faultaddr = 0x%(3)016lx, pt_base_mfn = %(4)d, fixup = 0x%(5)016lx ]
+0x0020f003  CPU%(cpu)d  %(tsc)d   except_page_fault_propagate [ vcpu_dom_err = 0x%(1)016lx, rip = 0x%(2)016lx, faultaddr = 0x%(3)016lx, pt_base_mfn = %(4)d ]
diff -r 840f33e54054 xen/arch/x86/dom0_ops.c
--- a/xen/arch/x86/dom0_ops.c	Sat Jun 17 01:45:45 2006
+++ b/xen/arch/x86/dom0_ops.c	Wed Jul 26 02:59:00 2006
@@ -24,6 +24,7 @@
 #include <asm/hvm/hvm.h>
 #include <asm/hvm/support.h>
 #include <asm/processor.h>
+#include <asm/desc.h>
 #include <public/sched_ctl.h>
 
 #include <asm/mtrr.h>
@@ -455,7 +456,16 @@
     else
     {
         /* IOPL privileges are virtualised: merge back into returned eflags. */
-        BUG_ON((c->user_regs.eflags & EF_IOPL) != 0);
+        //++MTY This crashes Xen sometimes (calls ud2 opcode as part of FORCE_CRASH)
+        //
+        // Call trace:
+        // arch_getdomaininfo_ctxt
+        // do_dom0_op
+        // get_page_froml1e
+        // do_iret
+        // syscall_entry
+        //
+        // BUG_ON((c->user_regs.eflags & EF_IOPL) != 0);
         c->user_regs.eflags |= v->arch.iopl << 12;
     }
 
@@ -468,6 +478,13 @@
         c->flags |= VGCF_HVM_GUEST;
 
     c->ctrlreg[3] = xen_pfn_to_cr3(pagetable_get_pfn(v->arch.guest_table));
+
+    /*
+     * Put Xen's common GDT in the appropriate slot of gdt_frames so
+     * the guest can map it. This is not an isolation or security
+     * problem since it's easily obtained from the Xen binary anyway.
+     */
+    c->gdt_frames[FIRST_RESERVED_GDT_PAGE] = virt_to_mfn(gdt_table);
 
     c->vm_assist = v->domain->vm_assist;
 }
diff -r 840f33e54054 xen/arch/x86/domain.c
--- a/xen/arch/x86/domain.c	Sat Jun 17 01:45:45 2006
+++ b/xen/arch/x86/domain.c	Wed Jul 26 02:59:00 2006
@@ -156,13 +156,15 @@
     xfree(v);
 }
 
+void share_m2p_pages_with_guest(struct domain *d);
+
 int arch_domain_create(struct domain *d)
 {
     l1_pgentry_t gdt_l1e;
     int vcpuid, pdpt_order, rc;
-#ifdef __x86_64__
+    //#ifdef __x86_64__
     int i;
-#endif
+    //#endif
 
     pdpt_order = get_order_from_bytes(PDPT_L1_ENTRIES * sizeof(l1_pgentry_t));
     d->arch.mm_perdomain_pt = alloc_xenheap_pages(pdpt_order);
@@ -226,6 +228,27 @@
         memset(d->shared_info, 0, PAGE_SIZE);
         share_xen_page_with_guest(
             virt_to_page(d->shared_info), d, XENSHARE_writable);
+
+        /*
+         * Share reserved GDT page(s) with guests so they can properly examine
+         * descriptors above FIRST_RESERVED_GDT_ENTRY. This is not an isolation
+         * issue since the GDT contains no private information and is read-only.
+         //
+         //++MTY TODO: Have these pages even been mapped inside Xen at this point?
+         //++MTY TODO: only copy in the MFNs inside arch_getdomaininfo_ctxt() - don't update the master gdt_frames list.
+         //
+         */
+        //printk("Common GDT page at %p is mfn %lu; granting to guest domain %d\n", gdt_table, virt_to_mfn(gdt_table), d->domain_id);
+        //share_xen_page_with_guest(virt_to_page(gdt_table), d, XENSHARE_readonly);
+
+        // We already shared with DOMID_XEN for the privileged guests:
+        // NO: This creates all kinds of havoc:
+        // if (d->domain_id) share_m2p_pages_with_guest(d);
+
+        //for (i = FIRST_RESERVED_GDT_PAGE; i < FIRST_RESERVED_GDT_PAGE + NR_RESERVED_GDT_PAGES; i++) {
+        ////++MTY add to gdt_frames[] array
+        //share_xen_page_with_guest(virt_to_page(GDT_VIRT_START(vcpu) + (i * PAGE_SIZE)), d, XENSHARE_readonly);
+        //}
     }
 
     return 0;
@@ -309,8 +332,13 @@
         hvm_load_cpu_guest_regs(v, &v->arch.guest_context.user_regs);
     }
 
-    if ( test_bit(_VCPUF_initialised, &v->vcpu_flags) )
+    if ( test_bit(_VCPUF_initialised, &v->vcpu_flags) ) {
+        update_vcpu_pt_base(v, c->ctrlreg[3] >> PAGE_SHIFT, 0);
+        if (d->domain_id > 0) printk("arch_set_info_guest: cpu already initialized (guest_table %lu, cr3 %lx)\n", v->arch.guest_table.pfn, v->arch.guest_context.ctrlreg[3]);
         return 0;
+    }
+
+    // otherwise take special initialization actions below
 
     memset(v->arch.guest_context.debugreg, 0,
            sizeof(v->arch.guest_context.debugreg));
@@ -391,6 +419,13 @@
             __copy_to_user(v->runstate_guest, &v->runstate,
                            sizeof(v->runstate));
 
+        break;
+    }
+
+    case VCPUOP_get_registered_runstate_memory_area: {
+        unsigned long runstate_virtaddr = (unsigned long)v->runstate_guest;
+        if (copy_to_guest(arg, &runstate_virtaddr, 1))
+            rc = -EFAULT;
         break;
     }
 
diff -r 840f33e54054 xen/arch/x86/mm.c
--- a/xen/arch/x86/mm.c	Sat Jun 17 01:45:45 2006
+++ b/xen/arch/x86/mm.c	Wed Jul 26 02:59:00 2006
@@ -146,7 +146,7 @@
 #define FOREIGNDOM (percpu_info[smp_processor_id()].foreign ?: current->domain)
 
 /* Private domain structs for DOMID_XEN and DOMID_IO. */
-static struct domain *dom_xen, *dom_io;
+struct domain *dom_xen, *dom_io;
 
 /* Frame table and its size in pages. */
 struct page_info *frame_table;
@@ -1712,34 +1712,40 @@
 }
 
 
-int new_guest_cr3(unsigned long mfn)
-{
-    struct vcpu *v = current;
+int update_vcpu_pt_base(struct vcpu *v, unsigned long mfn, int update_cr3)
+{
     struct domain *d = v->domain;
     int okay;
     unsigned long old_base_mfn;
 
     ASSERT(writable_pagetable_in_sync(d));
 
+    if (d->domain_id > 0) {
+        MEM_LOG("update_vcpu_cr3: domain %d, vcpu %d -> mfn %lu\n", d->domain_id, v->vcpu_id, mfn);
+    } 
+
     if ( shadow_mode_refcounts(d) )
     {
         okay = get_page_from_pagenr(mfn, d);
         if ( unlikely(!okay) )
         {
-            MEM_LOG("Error while installing new baseptr %lx", mfn);
+            MEM_LOG("Error while installing new baseptr %lu", mfn);
             return 0;
         }
     }
     else
     {
         okay = get_page_and_type_from_pagenr(mfn, PGT_root_page_table, d);
+        if ((d->domain_id > 0) && (!okay)) {
+            MEM_LOG("new_guest_cr3: get_page_and_type_from_pagenr: okay = %d\n", okay);
+        }
         if ( unlikely(!okay) )
         {
             /* Switch to idle pagetable: this VCPU has no active p.t. now. */
             old_base_mfn = pagetable_get_pfn(v->arch.guest_table);
             v->arch.guest_table = pagetable_null();
             update_pagetables(v);
-            write_cr3(__pa(idle_pg_table));
+            if (update_cr3) write_cr3(__pa(idle_pg_table));
             if ( old_base_mfn != 0 )
                 put_page_and_type(mfn_to_page(old_base_mfn));
 
@@ -1748,8 +1754,8 @@
             if ( !okay )
             {
                 /* Failure here is unrecoverable: the VCPU has no pagetable! */
-                MEM_LOG("Fatal error while installing new baseptr %lx", mfn);
-                domain_crash(d);
+                MEM_LOG("Fatal error while installing new baseptr %lu", mfn);
+                // domain_crash(d); // DO NOT DO THIS! It propagates crash back to dom0!
                 percpu_info[v->processor].deferred_ops = 0;
                 return 0;
             }
@@ -1762,7 +1768,10 @@
     v->arch.guest_table = pagetable_from_pfn(mfn);
     update_pagetables(v); /* update shadow_table and monitor_table */
 
-    write_ptbase(v);
+    if (update_cr3) {
+        write_ptbase(v);
+        if (d->domain_id > 0) MEM_LOG("new_guest_cr3: updating local cr3 for vcpu %d\n", v->vcpu_id);
+    }
 
     if ( likely(old_base_mfn != 0) )
     {
@@ -1783,6 +1792,7 @@
         get_shadow_ref(v->arch.monitor_shadow_ref);
     }
 
+    if (d->domain_id > 0) MEM_LOG("update_vcpu_pt_base: installed new baseptr %lu (guest_table = %lu)\n", mfn, v->arch.guest_table.pfn);
     return 1;
 }
 
@@ -1989,7 +1999,7 @@
             if ( shadow_mode_refcounts(d) )
                 break;
 
-            if ( unlikely(!(okay = get_page_from_pagenr(mfn, d))) )
+            if ( unlikely(!(okay = get_page_from_pagenr(mfn, FOREIGNDOM))) )
             {
                 MEM_LOG("Mfn %lx bad domain (dom=%p)",
                         mfn, page_get_owner(page));
@@ -2111,6 +2121,92 @@
                     percpu_info[cpu].deferred_ops |= DOP_RELOAD_LDT;
             }
             break;
+        }
+
+        /*
+         * PTLsim specific hypercalls
+         */
+
+        /* Get template GDT mapped by Xen into the FIRST_RESERVED_GDT_PAGE gdt_frames[] slot */
+
+        case MMUEXT_GET_GDT_TEMPLATE: {       
+            rc = -E2BIG;
+            if (op.arg2.nr_ents > PAGE_SIZE)
+                break;
+            
+            rc = -EFAULT;
+            if (copy_to_user((void*)op.arg1.linear_addr, &gdt_table, op.arg2.nr_ents))
+                break;
+            
+            rc = 0;
+            break;
+        }
+
+        /* New kernel or user page table base pointer for foreign domain's specified VCPU(s) */
+        case MMUEXT_SET_KERNEL_BASEPTR:
+        case MMUEXT_SET_USER_BASEPTR: {
+            struct vcpu *v;
+
+            rc = -EPERM;
+            if (FOREIGNDOM == current->domain)
+                /* Can't do this to ourselves */
+                break;
+
+            rc = -E2BIG;
+            if ((op.arg2.vcpuid < 0) || (op.arg2.vcpuid >= MAX_VIRT_CPUS))
+                break;
+
+            rc = -ENOENT;
+            if ((v = FOREIGNDOM->vcpu[op.arg2.vcpuid]) == NULL)
+                break;
+
+            if (op.cmd == MMUEXT_SET_KERNEL_BASEPTR) {
+                okay = update_vcpu_pt_base(v, mfn, 0);
+                if (unlikely(!okay)) {
+                    printk("Error while installing new mfn %lx as kernel baseptr in domain %d on vcpu %d",
+                           mfn, FOREIGNDOM->domain_id, v->vcpu_id);
+                    rc = -EINVAL;
+                }
+            } else {
+                okay = get_page_and_type_from_pagenr(mfn, PGT_root_page_table, FOREIGNDOM);
+                if (unlikely(!okay)) {
+                    printk("Error while installing new mfn %lx as user baseptr in domain %d on vcpu %d",
+                           mfn, FOREIGNDOM->domain_id, v->vcpu_id);
+                    rc = -EINVAL;
+                } else {
+                    unsigned long old_mfn = pagetable_get_pfn(v->arch.guest_table_user);
+                    v->arch.guest_table_user = pagetable_from_pfn(mfn);
+                    if ( old_mfn != 0 )
+                        put_page_and_type(mfn_to_page(old_mfn));
+                }
+                break;
+            }
+
+            break;
+        }
+
+        case MMUEXT_GET_KERNEL_BASEPTR:
+        case MMUEXT_GET_USER_BASEPTR: {
+            struct vcpu *v;
+
+            rc = -E2BIG;
+            if ((op.arg2.vcpuid < 0) || (op.arg2.vcpuid >= MAX_VIRT_CPUS))
+                break;
+
+            rc = -ENOENT;
+            if ((v = FOREIGNDOM->vcpu[op.arg2.vcpuid]) == NULL)
+                break;
+
+            mfn = (op.cmd == MMUEXT_GET_KERNEL_BASEPTR)
+                ? pagetable_get_pfn(v->arch.guest_table)
+                : pagetable_get_pfn(v->arch.guest_table_user);
+
+            rc = -EFAULT;
+            if (copy_to_user((void*)op.arg1.linear_addr, &mfn, sizeof(mfn)))
+                break;
+
+            rc = 0;
+            break;            
         }
 
         default:
diff -r 840f33e54054 xen/arch/x86/setup.c
--- a/xen/arch/x86/setup.c	Sat Jun 17 01:45:45 2006
+++ b/xen/arch/x86/setup.c	Wed Jul 26 02:59:00 2006
@@ -628,7 +628,7 @@
 
 #elif defined(CONFIG_X86_64)
 
-    p += sprintf(p, "xen-%d.%d-x86_64 ", XEN_VERSION, XEN_SUBVERSION);
+    p += sprintf(p, "xen-%d.%d-x86_64-ptlsim ", XEN_VERSION, XEN_SUBVERSION);
     if ( hvm_enabled )
     {
         p += sprintf(p, "hvm-%d.%d-x86_32 ", XEN_VERSION, XEN_SUBVERSION);
diff -r 840f33e54054 xen/arch/x86/time.c
--- a/xen/arch/x86/time.c	Sat Jun 17 01:45:45 2006
+++ b/xen/arch/x86/time.c	Wed Jul 26 02:59:00 2006
@@ -4,7 +4,9 @@
  * Per-CPU time calibration and management.
  * 
  * Copyright (c) 2002-2005, K A Fraser
- * 
+ *
+ * CPU frequency scaling support: Matt T. Yourst <yourst@yourst.com> 
+ *
  * Portions from Linux are:
  * Copyright (c) 1991, 1992, 1995  Linus Torvalds
  */
@@ -85,6 +87,15 @@
 static inline u32 div_frac(u32 dividend, u32 divisor)
 {
     u32 quotient, remainder;
+
+    if (divisor == dividend) {
+        return 0xffffffff; /* a.k.a. 0.99999, as close as we can */
+    }
+
+    if (!divisor) {
+        return 0; /* avoid divide-by-zero at all costs */
+    }
+
     ASSERT(dividend < divisor);
     __asm__ ( 
         "divl %4"
@@ -914,6 +925,141 @@
     setup_irq(0, &irq0);
 }
 
+/*
+ * Frequency Scaling Support
+ *
+ * These functions are called from emulate_privileged_op
+ * in response to the MSR writes that control core frequency
+ * and voltage on various CPU types.
+ *
+ * We identify only those writes that alter the frequency
+ * itself (i.e. between raising or lowering the voltage
+ * appropriately) and make sure that the requested frequency
+ * is different from the current frequency. In this case
+ * we read the appropriate status MSR until the frequency
+ * stabilizes, then recalibrate all hypervisor timing
+ * variables to the new frequency as indicated in the MSR.
+ *
+ * The frequency change is effective on the CPU this code
+ * is called on: it's the responsibility of the guest OS
+ * to only write the virtual MSR on the target CPU context.
+ *
+ * No modifications to the guest OS cpufreq drivers are
+ * needed as long as support is provided below for the
+ * corresponding CPU type.
+ */
+
+/*
+ * AMD Athlon 64 / Opteron Support (from powernow-k8 driver):
+ */
+
+/*
+ * According to the AMD manuals, the following formula
+ * always converts an FID to the actual frequency,
+ * based on increments of 100 MHz (200 MHz steps):
+ *
+ *   mhz = 800 + 100*fid
+ *
+ * Technically the BIOS is supposed to provide this
+ * table (so matching voltages can be found), but
+ * the frequency part is fixed for all K8 cores,
+ * so we just hard code the following formula:
+ */
+static inline int k8_fid_to_mhz(int fid) {
+    return 800 + 100*fid;
+}
+
+int handle_k8_fidvid_status_msr_read(u32* lo, u32* hi) {
+    /* This will return -1 if the processor isn't a K8: */
+    return rdmsr_safe(MSR_FIDVID_STATUS, *lo, *hi);
+}
+
+static int k8_fidvid_wait(void) {
+	u32 lo, hi;
+	u32 i = 0;
+
+    DPRINTK("k8_fidvid_wait: waiting for frequency and voltage to stabilize...");
+
+	do {
+        if (i++ > 10000) {
+            printk("k8_vidfid_wait: Excessive wait time for vid/fid to stabilize\n");
+            return -1;
+		}
+        rdmsr_safe(MSR_FIDVID_STATUS, lo, hi);
+	} while (lo & MSR_S_LO_CHANGE_PENDING);
+
+    DPRINTK("OK: new fid %d\n", lo & MSR_S_LO_CHANGE_PENDING);
+
+    return lo & MSR_S_LO_CURRENT_FID;
+}
+
+#if 0
+#undef DPRINTK
+#define DPRINTK printk
+#endif
+
+int handle_k8_fidvid_ctl_msr_write(u32 lo, u32 hi) {
+    int rc;
+    u32 oldlo, oldhi;
+    int oldfid, newfid;
+    int mhz;
+    unsigned int cpu = smp_processor_id();
+    s_time_t now;
+
+    DPRINTK("fidvid_ctl: requested msr write 0x%08x:0x%08x\n", hi, lo);
+
+    rc = rdmsr_safe(MSR_FIDVID_STATUS, oldlo, oldhi);
+    /* This will return -1 if the processor isn't a K8: */
+    if (rc) return rc;
+
+    oldfid = (oldlo & MSR_S_LO_CURRENT_FID);
+    newfid = (lo & MSR_C_LO_NEW_FID);
+
+    if (oldfid != newfid) {
+        DPRINTK("fidvid_ctl: moving from old fid %d to new fid %d\n", oldfid, newfid);
+    } else {
+        DPRINTK("fidvid_ctl: same fid %d\n", oldfid);
+    }
+
+    DPRINTK("fidvid_ctl: writing MSR 0x%08x with 0x%08x:0x%08x...\n", MSR_FIDVID_CTL, hi, lo);
+
+    rc = wrmsr_safe(MSR_FIDVID_CTL, lo, hi);
+    if (rc) return rc;
+
+    if (oldfid == newfid) return 0;
+
+    /* Only do the stabilization wait if we're changing the frequency */
+    /* For voltage changes, the OS will do this itself */
+
+    newfid = k8_fidvid_wait();
+    /* excessive wait? abort the change and let guest kernel figure it out */
+    if (newfid < 0) return 0;
+
+    DPRINTK("fidvid_ctl: recalibrating TSC...");
+
+    mhz = k8_fid_to_mhz(newfid);
+    DPRINTK("%d MHz\n", mhz);
+
+    cpu_khz = mhz * 1000;
+    set_time_scale(&cpu_time[smp_processor_id()].tsc_scale, (u64)mhz * 1000000ULL);
+
+    DPRINTK("fidvid_ctl: resetting timestamps...");
+
+    rdtscll(cpu_time[cpu].local_tsc_stamp);
+    now = read_platform_stime();
+
+    cpu_time[cpu].stime_master_stamp = now;
+    cpu_time[cpu].stime_local_stamp  = now;
+
+    DPRINTK("fidvid_ctl: recalibrating timers...");
+
+    local_time_calibration(NULL);
+    __update_vcpu_system_time(current);
+    DPRINTK("OK\n");
+
+    return 0;
+}
+
 void send_timer_event(struct vcpu *v)
 {
     send_guest_vcpu_virq(v, VIRQ_TIMER);
diff -r 840f33e54054 xen/arch/x86/traps.c
--- a/xen/arch/x86/traps.c	Sat Jun 17 01:45:45 2006
+++ b/xen/arch/x86/traps.c	Wed Jul 26 02:59:00 2006
@@ -44,6 +44,7 @@
 #include <xen/symbols.h>
 #include <xen/iocap.h>
 #include <xen/nmi.h>
+#include <xen/trace.h>
 #include <asm/shadow.h>
 #include <asm/system.h>
 #include <asm/io.h>
@@ -757,19 +758,25 @@
  */
 asmlinkage int do_page_fault(struct cpu_user_regs *regs)
 {
-    unsigned long addr, fixup;
+    unsigned long addr, fixup, pt_base_mfn;
     int rc;
 
     ASSERT(!in_irq());
 
     __asm__ __volatile__ ("mov %%cr2,%0" : "=r" (addr) : );
+    __asm__ __volatile__ ("mov %%cr3,%0" : "=r" (pt_base_mfn) : );
+    pt_base_mfn >>= 12; // get actual mfn
 
     DEBUGGER_trap_entry(TRAP_page_fault, regs);
 
     perfc_incrc(page_faults);
 
-    if ( unlikely((rc = fixup_page_fault(addr, regs)) != 0) )
+    if ( unlikely((rc = fixup_page_fault(addr, regs)) != 0) ) {
+        TRACE_5D(TRC_EXCEPT_PAGE_FAULT_FIXABLE, 
+                 ((regs->error_code << 0) & 0xffff) | ((unsigned long)current->domain->domain_id << 16) | ((unsigned long)current->vcpu_id << 32), 
+                 regs->eip, addr, pt_base_mfn, 0);
         return rc;
+    }
 
     if ( unlikely(!guest_mode(regs)) )
     {
@@ -777,11 +784,17 @@
         {
             DPRINTK("Spurious fault in domain %u:%u at addr %lx\n",
                     current->domain->domain_id, current->vcpu_id, addr);
+            TRACE_5D(TRC_EXCEPT_PAGE_FAULT_SPURIOUS, 
+                     ((regs->error_code << 0) & 0xffff) | ((unsigned long)current->domain->domain_id << 16) | ((unsigned long)current->vcpu_id << 32), 
+                     regs->eip, addr, pt_base_mfn, 0);
             return EXCRET_not_a_fault;
         }
 
         if ( likely((fixup = search_exception_table(regs->eip)) != 0) )
         {
+            TRACE_5D(TRC_EXCEPT_PAGE_FAULT_CHECKED,
+                     ((regs->error_code << 0) & 0xffff) | ((unsigned long)current->domain->domain_id << 16) | ((unsigned long)current->vcpu_id << 32), 
+                     regs->eip, addr, pt_base_mfn, fixup);
             perfc_incrc(copy_user_faults);
             regs->eip = fixup;
             return 0;
@@ -797,6 +810,10 @@
               smp_processor_id(), regs->error_code, _p(addr));
     }
 
+    TRACE_5D(TRC_EXCEPT_PAGE_FAULT_PROPAGATE,
+             ((regs->error_code << 0) & 0xffff) | ((unsigned long)current->domain->domain_id << 16) | ((unsigned long)current->vcpu_id << 32), 
+             regs->eip, addr, pt_base_mfn, 0);
+    
     propagate_page_fault(addr, regs->error_code);
     return 0;
 }
@@ -1221,6 +1238,16 @@
                 ((u64)regs->edx << 32) | regs->eax;
             break;
 #endif
+        case MSR_FIDVID_CTL: {
+            extern int handle_k8_fidvid_ctl_msr_write(u32 lo, u32 hi);
+            /* domU is never allowed to mess with core frequencies and voltages */
+            if (!IS_PRIV(current->domain))
+                break;
+            if (handle_k8_fidvid_ctl_msr_write(regs->eax, regs->edx))
+                goto fail;
+            break;
+        }
+
         default:
             if ( (rdmsr_safe(regs->ecx, l, h) != 0) ||
                  (regs->eax != l) || (regs->edx != h) )
@@ -1252,6 +1279,14 @@
             if ( rdmsr_safe(regs->ecx, regs->eax, regs->edx) )
                 goto fail;
             break;
+
+        case MSR_FIDVID_STATUS: {
+            extern int handle_k8_fidvid_status_msr_read(u32* lo, u32* hi);
+            if (handle_k8_fidvid_status_msr_read((u32*)&regs->eax, (u32*)&regs->edx))
+                goto fail;
+            break;
+        }
+
         default:
             /* Everyone can read the MSR space. */
             /*DPRINTK("Domain attempted RDMSR %p.\n", _p(regs->ecx));*/
diff -r 840f33e54054 xen/arch/x86/x86_64/entry.S
--- a/xen/arch/x86/x86_64/entry.S	Sat Jun 17 01:45:45 2006
+++ b/xen/arch/x86/x86_64/entry.S	Wed Jul 26 02:59:00 2006
@@ -337,6 +337,14 @@
         jnz   test_all_events
         jmp   restore_all_xen
 
+.data
+ENTRY(last_exception_type)
+  .int 0
+
+ENTRY(last_exception_error_code)
+  .int 0
+.previous
+
         ALIGN
 /* No special register assumptions. */
 handle_exception:
@@ -345,7 +353,12 @@
         jz    exception_with_ints_disabled
         sti
         movq  %rsp,%rdi
+        movl  UREGS_error_code(%rsp),%eax
+        leaq  last_exception_error_code(%rip),%rdx
+        movl  %eax,(%rdx)
         movl  UREGS_entry_vector(%rsp),%eax
+        leaq  last_exception_type(%rip),%rdx
+        movl  %eax,(%rdx)
         leaq  exception_table(%rip),%rdx
         GET_CURRENT(%rbx)
         PERFC_INCR(PERFC_exceptions, %rax)
diff -r 840f33e54054 xen/arch/x86/x86_64/mm.c
--- a/xen/arch/x86/x86_64/mm.c	Sat Jun 17 01:45:45 2006
+++ b/xen/arch/x86/x86_64/mm.c	Wed Jul 26 02:59:00 2006
@@ -74,6 +74,9 @@
     return pl2e;
 }
 
+static struct page_info* l3_mpt_page;
+static struct page_info* l2_mpt_page;
+
 void __init paging_init(void)
 {
     unsigned long i, mpt_size;
@@ -86,11 +89,13 @@
 
     /* Create user-accessible L2 directory to map the MPT for guests. */
     l3_ro_mpt = alloc_xenheap_page();
+    l3_mpt_page = (struct page_info*)l3_ro_mpt;
     clear_page(l3_ro_mpt);
     idle_pg_table[l4_table_offset(RO_MPT_VIRT_START)] =
         l4e_from_page(
             virt_to_page(l3_ro_mpt), __PAGE_HYPERVISOR | _PAGE_USER);
     l2_ro_mpt = alloc_xenheap_page();
+    l2_mpt_page = (struct page_info*)l2_ro_mpt;
     clear_page(l2_ro_mpt);
     l3_ro_mpt[l3_table_offset(RO_MPT_VIRT_START)] =
         l3e_from_page(
@@ -103,6 +108,11 @@
      */
     mpt_size  = (max_page * BYTES_PER_LONG) + (1UL << L2_PAGETABLE_SHIFT) - 1;
     mpt_size &= ~((1UL << L2_PAGETABLE_SHIFT) - 1UL);
+    // define L2_PAGETABLE_SHIFT      21
+    // with 2^40 pages,   (max_page * BYTES_PER_LONG) + (1UL << L2_PAGETABLE_SHIFT) - 1;
+    // (1<<40) * 8) + (1 << 21) - 1;
+
+    // for 2 GB phys mem, this should be 2 iterations:
     for ( i = 0; i < (mpt_size >> L2_PAGETABLE_SHIFT); i++ )
     {
         if ( (pg = alloc_domheap_pages(NULL, PAGETABLE_ORDER, 0)) == NULL )
@@ -135,12 +145,48 @@
     flush_tlb_all_pge();
 }
 
-void subarch_init_memory(void)
-{
+
+void share_m2p_pages_with_guest(struct domain *d) {
     unsigned long i, v, m2p_start_mfn;
     l3_pgentry_t l3e;
     l2_pgentry_t l2e;
-
+#if 0
+    if (d->domain_id && (d->domain_id != DOMID_XEN)) {
+        /* Allow simulated traversal for PTLsim */
+        printk("Sharing read-only MPT L3 page table page mfn %lu with domain %d\n", page_to_mfn(l3_mpt_page), d->domain_id);
+        share_xen_page_with_guest(l3_mpt_page, d, XENSHARE_readonly);
+        printk("Sharing read-only MPT L2 page table page mfn %lu with domain %d\n", page_to_mfn(l3_mpt_page), d->domain_id);
+        share_xen_page_with_guest(l2_mpt_page, d, XENSHARE_readonly);
+    }
+#endif
+    /* M2P table is mappable read-only by specified domain. */
+    for ( v  = RDWR_MPT_VIRT_START; 
+          v != RDWR_MPT_VIRT_END;
+          v += 1 << L2_PAGETABLE_SHIFT )
+    {
+        l3e = l4e_to_l3e(idle_pg_table[l4_table_offset(v)])[
+            l3_table_offset(v)];
+        if ( !(l3e_get_flags(l3e) & _PAGE_PRESENT) )
+            continue;
+        l2e = l3e_to_l2e(l3e)[l2_table_offset(v)];
+        if ( !(l2e_get_flags(l2e) & _PAGE_PRESENT) )
+            continue;
+        m2p_start_mfn = l2e_get_pfn(l2e);
+
+        printk("Sharing %d MPT pages with domain %d\n", L1_PAGETABLE_ENTRIES, d->domain_id);
+
+        for ( i = 0; i < L1_PAGETABLE_ENTRIES; i++ )
+        {
+            struct page_info *page = mfn_to_page(m2p_start_mfn + i);
+            share_xen_page_with_guest(page, d, XENSHARE_readonly);
+        }
+    }
+}
+
+extern struct domain *dom_xen, *dom_io;
+
+void subarch_init_memory(void)
+{
     /*
      * We are rather picky about the layout of 'struct page_info'. The
      * count_info and domain fields must be adjacent, as we perform atomic
@@ -153,25 +199,7 @@
                  (32 + BITS_TO_LONGS(NR_CPUS)*sizeof(long)));
 
     /* M2P table is mappable read-only by privileged domains. */
-    for ( v  = RDWR_MPT_VIRT_START; 
-          v != RDWR_MPT_VIRT_END;
-          v += 1 << L2_PAGETABLE_SHIFT )
-    {
-        l3e = l4e_to_l3e(idle_pg_table[l4_table_offset(v)])[
-            l3_table_offset(v)];
-        if ( !(l3e_get_flags(l3e) & _PAGE_PRESENT) )
-            continue;
-        l2e = l3e_to_l2e(l3e)[l2_table_offset(v)];
-        if ( !(l2e_get_flags(l2e) & _PAGE_PRESENT) )
-            continue;
-        m2p_start_mfn = l2e_get_pfn(l2e);
-
-        for ( i = 0; i < L1_PAGETABLE_ENTRIES; i++ )
-        {
-            struct page_info *page = mfn_to_page(m2p_start_mfn + i);
-            share_xen_page_with_privileged_guests(page, XENSHARE_readonly);
-        }
-    }
+    share_m2p_pages_with_guest(dom_xen);
 }
 
 long subarch_memory_op(int op, XEN_GUEST_HANDLE(void) arg)
diff -r 840f33e54054 xen/arch/x86/x86_64/traps.c
--- a/xen/arch/x86/x86_64/traps.c	Sat Jun 17 01:45:45 2006
+++ b/xen/arch/x86/x86_64/traps.c	Wed Jul 26 02:59:00 2006
@@ -21,6 +21,18 @@
 
 #include <public/callback.h>
 
+#define TRAP_COUNT 20
+static char *trap_name[TRAP_COUNT] = { 
+    "divide error", "debug", "nmi", "bkpt",
+    "overflow", "bounds", "invalid opcode", "device not available",
+    "double fault",  "coprocessor segment", "invalid tss", "segment not found", 
+    "stack error", "general protection fault", "page fault", "spurious interrupt",
+    "coprocessor error", "alignment check", "machine check", "simd error"
+};
+
+extern unsigned int last_exception_type;
+extern unsigned int last_exception_error_code;
+
 void show_registers(struct cpu_user_regs *regs)
 {
     struct cpu_user_regs fault_regs = *regs;
@@ -47,6 +59,8 @@
     printk("----[ Xen-%d.%d%s    %s ]----\n",
            XEN_VERSION, XEN_SUBVERSION, XEN_EXTRAVERSION,
            print_tainted(taint_str));
+    printk("Trap: %s (%d)\n", (last_exception_type < TRAP_COUNT) ? trap_name[last_exception_type] : "Unknown", last_exception_type);
+    printk("Error code %08x\n", last_exception_error_code);
     printk("CPU:    %d\nRIP:    %04x:[<%016lx>]",
            smp_processor_id(), fault_regs.cs, fault_regs.rip);
     if ( !guest_mode(regs) )
diff -r 840f33e54054 xen/common/event_channel.c
--- a/xen/common/event_channel.c	Sat Jun 17 01:45:45 2006
+++ b/xen/common/event_channel.c	Wed Jul 26 02:59:00 2006
@@ -24,11 +24,14 @@
 #include <xen/irq.h>
 #include <xen/iocap.h>
 #include <xen/guest_access.h>
+#include <xen/trace.h>
 #include <asm/current.h>
 
 #include <public/xen.h>
 #include <public/event_channel.h>
 #include <acm/acm_hooks.h>
+
+#define ENABLE_EVENT_DEBUG
 
 #define bucket_from_port(d,p) \
     ((d)->evtchn[(p)/EVTCHNS_PER_BUCKET])
@@ -442,11 +445,14 @@
     struct evtchn *lchn, *rchn;
     struct domain *ld = current->domain, *rd;
     int            rport, ret = 0;
+    struct vcpu *vt;
 
     spin_lock(&ld->evtchn_lock);
 
     if ( unlikely(!port_is_valid(ld, lport)) )
     {
+        TRACE_5D(TRC_EVTCHN_SEND, 0,
+                 ((current->domain->domain_id << 16) | current->vcpu_id), lport, 0, 0);
         spin_unlock(&ld->evtchn_lock);
         return -EINVAL;
     }
@@ -458,15 +464,31 @@
         rd    = lchn->u.interdomain.remote_dom;
         rport = lchn->u.interdomain.remote_port;
         rchn  = evtchn_from_port(rd, rport);
+        vt = rd->vcpu[rchn->notify_vcpu_id];
+
+        TRACE_5D(TRC_EVTCHN_SEND, 1,
+                 ((current->domain->domain_id << 16) | current->vcpu_id), lport,
+                 ((rd->domain_id << 16) | vt->vcpu_id), rport);
+
         evtchn_set_pending(rd->vcpu[rchn->notify_vcpu_id], rport);
         break;
     case ECS_IPI:
+        TRACE_5D(TRC_EVTCHN_SEND, 2,
+                 ((current->domain->domain_id << 16) | current->vcpu_id), lport,
+                 ((ld->domain_id << 16) | ld->vcpu[lchn->notify_vcpu_id]->vcpu_id), lport);
+
         evtchn_set_pending(ld->vcpu[lchn->notify_vcpu_id], lport);
         break;
     case ECS_UNBOUND:
+        TRACE_5D(TRC_EVTCHN_SEND, 3,
+                 ((current->domain->domain_id << 16) | current->vcpu_id), lport,
+                 0, 0);
         /* silently drop the notification */
         break;
     default:
+        TRACE_5D(TRC_EVTCHN_SEND, 4,
+                 ((current->domain->domain_id << 16) | current->vcpu_id), lport,
+                 0, 0);
         ret = -EINVAL;
     }
 
@@ -474,7 +496,6 @@
 
     return ret;
 }
-
 
 void evtchn_set_pending(struct vcpu *v, int port)
 {
@@ -488,24 +509,42 @@
      * others may require explicit memory barriers.
      */
 
-    if ( test_and_set_bit(port, s->evtchn_pending) )
-        return;
+    int action_taken = 0;
+
+    if ( test_and_set_bit(port, s->evtchn_pending) ) {
+        action_taken = 1;
+        goto out;
+    }
 
     if ( !test_bit        (port, s->evtchn_mask) &&
          !test_and_set_bit(port / BITS_PER_LONG,
                            &v->vcpu_info->evtchn_pending_sel) )
     {
+        action_taken = 2;
         vcpu_mark_events_pending(v);
-    }
-    
+    } else {
+        action_taken = 3;
+    }
+
     /* Check if some VCPU might be polling for this event. */
     if ( unlikely(test_bit(_DOMF_polling, &d->domain_flags)) &&
          likely(test_and_clear_bit(_DOMF_polling, &d->domain_flags)) )
     {
         for_each_vcpu ( d, v )
-            if ( test_and_clear_bit(_VCPUF_polling, &v->vcpu_flags) )
+            if ( test_and_clear_bit(_VCPUF_polling, &v->vcpu_flags) ) {
+                action_taken |= 0x10;
                 vcpu_unblock(v);
-    }
+            }
+    }
+
+  out:
+    TRACE_5D(TRC_EVTCHN_SET_PENDING, d->domain_id, v->vcpu_id, port, 
+             (test_bit(port, s->evtchn_mask) & 1 << 0) |
+             ((test_bit(port, s->evtchn_pending) & 1) << 4) |
+             ((v->vcpu_info->evtchn_upcall_mask & 1) << 8) | 
+             ((v->vcpu_info->evtchn_upcall_pending & 1) << 12) |
+             (test_bit(port / BITS_PER_LONG, &v->vcpu_info->evtchn_pending_sel) << 16),
+             action_taken);
 }
 
 
@@ -516,8 +555,12 @@
     ASSERT(!virq_is_global(virq));
 
     port = v->virq_to_evtchn[virq];
-    if ( unlikely(port == 0) )
+    if ( unlikely(port == 0) ) {
+        TRACE_5D(TRC_EVTCHN_SEND_VCPU_VIRQ, v->domain->domain_id, v->vcpu_id, virq, port, 0);
         return;
+    }
+
+    TRACE_5D(TRC_EVTCHN_SEND_VCPU_VIRQ, v->domain->domain_id, v->vcpu_id, virq, port, 1);
 
     evtchn_set_pending(v, port);
 }
@@ -530,10 +573,15 @@
     ASSERT(virq_is_global(virq));
 
     port = d->vcpu[0]->virq_to_evtchn[virq];
-    if ( unlikely(port == 0) )
+    if ( unlikely(port == 0) ) {
+        TRACE_5D(TRC_EVTCHN_SEND_GLOBAL_VIRQ, d->domain_id, d->vcpu[0]->vcpu_id, virq, port, 0);
         return;
+    }
 
     chn = evtchn_from_port(d, port);
+
+    TRACE_5D(TRC_EVTCHN_SEND_GLOBAL_VIRQ, d->domain_id, d->vcpu[0]->vcpu_id, virq, port, 1);
+
     evtchn_set_pending(d->vcpu[chn->notify_vcpu_id], port);
 }
 
@@ -663,6 +711,7 @@
     shared_info_t *s = d->shared_info;
     int            port = unmask->port;
     struct vcpu   *v;
+    int action_taken = 0;
 
     spin_lock(&d->evtchn_lock);
 
@@ -684,7 +733,16 @@
                             &v->vcpu_info->evtchn_pending_sel) )
     {
         vcpu_mark_events_pending(v);
-    }
+        action_taken = 1;
+    }
+
+    TRACE_5D(TRC_EVTCHN_UNMASK, d->domain_id, v->vcpu_id, port, 
+             (test_bit(port, s->evtchn_mask) << 0) |
+             (test_bit(port, s->evtchn_pending) << 4) |
+             ((v->vcpu_info->evtchn_upcall_mask & 1) << 12) | 
+             ((v->vcpu_info->evtchn_upcall_pending & 1) << 16) |
+             (test_bit(port / BITS_PER_LONG, &v->vcpu_info->evtchn_pending_sel) << 20),
+             action_taken);
 
     spin_unlock(&d->evtchn_lock);
 
diff -r 840f33e54054 xen/include/asm-x86/mm.h
--- a/xen/include/asm-x86/mm.h	Sat Jun 17 01:45:45 2006
+++ b/xen/include/asm-x86/mm.h	Wed Jul 26 02:59:00 2006
@@ -7,6 +7,7 @@
 #include <xen/list.h>
 #include <asm/io.h>
 #include <asm/uaccess.h>
+#include <asm/current.h>
 
 /*
  * Per-page-frame information.
@@ -379,7 +380,11 @@
 
 #endif
 
-int new_guest_cr3(unsigned long pfn);
+int update_vcpu_pt_base(struct vcpu *v, unsigned long mfn, int update_cr3);
+
+static inline int new_guest_cr3(unsigned long mfn) {
+  return update_vcpu_pt_base(current, mfn, 1);
+}
 
 void propagate_page_fault(unsigned long addr, u16 error_code);
 
diff -r 840f33e54054 xen/include/asm-x86/msr.h
--- a/xen/include/asm-x86/msr.h	Sat Jun 17 01:45:45 2006
+++ b/xen/include/asm-x86/msr.h	Wed Jul 26 02:59:00 2006
@@ -137,6 +137,37 @@
 #define EFER_LMA (1<<_EFER_LMA)
 #define EFER_NX (1<<_EFER_NX)
 #define EFER_SVME (1<<_EFER_SVME)
+
+/* Model Specific Registers for K8 p-state transitions. MSRs are 64-bit. For */
+/* writes (wrmsr - opcode 0f 30), the register number is placed in ecx, and   */
+/* the value to write is placed in edx:eax. For reads (rdmsr - opcode 0f 32), */
+/* the register number is placed in ecx, and the data is returned in edx:eax. */
+
+#define MSR_FIDVID_CTL      0xc0010041
+#define MSR_FIDVID_STATUS   0xc0010042
+
+/* Field definitions within the FID VID Low Control MSR : */
+#define MSR_C_LO_INIT_FID_VID     0x00010000
+#define MSR_C_LO_NEW_VID          0x00003f00
+#define MSR_C_LO_NEW_FID          0x0000003f
+#define MSR_C_LO_VID_SHIFT        8
+
+/* Field definitions within the FID VID High Control MSR : */
+#define MSR_C_HI_STP_GNT_TO 	  0x000fffff
+
+/* Field definitions within the FID VID Low Status MSR : */
+#define MSR_S_LO_CHANGE_PENDING   0x80000000   /* cleared when completed */
+#define MSR_S_LO_MAX_RAMP_VID     0x3f000000
+#define MSR_S_LO_MAX_FID          0x003f0000
+#define MSR_S_LO_START_FID        0x00003f00
+#define MSR_S_LO_CURRENT_FID      0x0000003f
+
+/* Field definitions within the FID VID High Status MSR : */
+#define MSR_S_HI_MIN_WORKING_VID  0x3f000000
+#define MSR_S_HI_MAX_WORKING_VID  0x003f0000
+#define MSR_S_HI_START_VID        0x00003f00
+#define MSR_S_HI_CURRENT_VID      0x0000003f
+#define MSR_C_HI_STP_GNT_BENIGN	  0x00000001
 
 /* Intel MSRs. Some also available on other CPUs */
 #define MSR_IA32_PLATFORM_ID	0x17
diff -r 840f33e54054 xen/include/public/trace.h
--- a/xen/include/public/trace.h	Sat Jun 17 01:45:45 2006
+++ b/xen/include/public/trace.h	Wed Jul 26 02:59:00 2006
@@ -15,6 +15,8 @@
 #define TRC_DOM0OP  0x0004f000    /* Xen DOM0 operation trace */
 #define TRC_VMX     0x0008f000    /* Xen VMX trace            */
 #define TRC_MEM     0x000af000    /* Xen memory trace         */
+#define TRC_EVTCHN  0x0010f000    /* Event channel operations */
+#define TRC_EXCEPT  0x0020f000    /* Exceptions               */
 #define TRC_ALL     0xfffff000
 
 /* Trace subclasses */
@@ -55,6 +57,17 @@
 
 #define TRC_VMX_INT             (TRC_VMXINT + 1)
 
+#define TRC_EVTCHN_SEND                (TRC_EVTCHN + 1)
+#define TRC_EVTCHN_SET_PENDING         (TRC_EVTCHN + 2)
+#define TRC_EVTCHN_UNMASK              (TRC_EVTCHN + 3)
+#define TRC_EVTCHN_SEND_VCPU_VIRQ      (TRC_EVTCHN + 4)
+#define TRC_EVTCHN_SEND_GLOBAL_VIRQ    (TRC_EVTCHN + 5)
+#define TRC_EVTCHN_SEND_PIRQ           (TRC_EVTCHN + 6)
+
+#define TRC_EXCEPT_PAGE_FAULT_FIXABLE   (TRC_EXCEPT + 0)
+#define TRC_EXCEPT_PAGE_FAULT_SPURIOUS  (TRC_EXCEPT + 1)
+#define TRC_EXCEPT_PAGE_FAULT_CHECKED   (TRC_EXCEPT + 2)
+#define TRC_EXCEPT_PAGE_FAULT_PROPAGATE (TRC_EXCEPT + 3)
 
 /* This structure represents a single trace buffer record. */
 struct t_rec {
diff -r 840f33e54054 xen/include/public/vcpu.h
--- a/xen/include/public/vcpu.h	Sat Jun 17 01:45:45 2006
+++ b/xen/include/public/vcpu.h	Wed Jul 26 02:59:00 2006
@@ -108,6 +108,9 @@
 };
 typedef struct vcpu_register_runstate_memory_area vcpu_register_runstate_memory_area_t;
 
+/* PTLsim specific */
+#define VCPUOP_get_registered_runstate_memory_area 6
+
 #endif /* __XEN_PUBLIC_VCPU_H__ */
 
 /*
diff -r 840f33e54054 xen/include/public/xen.h
--- a/xen/include/public/xen.h	Sat Jun 17 01:45:45 2006
+++ b/xen/include/public/xen.h	Wed Jul 26 02:59:00 2006
@@ -192,13 +192,20 @@
 #define MMUEXT_SET_LDT          13
 #define MMUEXT_NEW_USER_BASEPTR 15
 
+/* PTLsim specific calls */
+#define MMUEXT_GET_GDT_TEMPLATE     32
+#define MMUEXT_GET_KERNEL_BASEPTR   33
+#define MMUEXT_SET_KERNEL_BASEPTR   34
+#define MMUEXT_GET_USER_BASEPTR     35
+#define MMUEXT_SET_USER_BASEPTR     36
+
 #ifndef __ASSEMBLY__
 struct mmuext_op {
     unsigned int cmd;
     union {
         /* [UN]PIN_TABLE, NEW_BASEPTR, NEW_USER_BASEPTR */
         xen_pfn_t     mfn;
-        /* INVLPG_LOCAL, INVLPG_ALL, SET_LDT */
+        /* INVLPG_LOCAL, INVLPG_ALL, SET_LDT, GET_GDT_TEMPLATE */
         unsigned long linear_addr;
     } arg1;
     union {
@@ -206,6 +213,8 @@
         unsigned int nr_ents;
         /* TLB_FLUSH_MULTI, INVLPG_MULTI */
         void *vcpumask;
+        /* NEW_BASEPTR_EXT, NEW_USER_BASEPTR_EXT */
+        unsigned int vcpuid;
     } arg2;
 };
 typedef struct mmuext_op mmuext_op_t;
