<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">

<!--Converted with LaTeX2HTML 2002-2-1 (1.70)
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<HTML>
<HEAD>
<TITLE>Performance Counters</TITLE>
<META NAME="description" CONTENT="Performance Counters">
<META NAME="keywords" CONTENT="PTLsimManual">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">

<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=iso-8859-1">
<META NAME="Generator" CONTENT="LaTeX2HTML v2002-2-1">
<META HTTP-EQUIV="Content-Style-Type" CONTENT="text/css">

<LINK REL="STYLESHEET" HREF="PTLsimManual.css">

<LINK REL="previous" HREF="node21.html">
<LINK REL="up" HREF="node20.html">
</HEAD>

<BODY >
<!--Navigation Panel-->
<IMG WIDTH="81" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next_inactive" SRC="nx_grp_g.png"> 
<A NAME="tex2html665"
  HREF="node20.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up" SRC="up.png"></A> 
<A NAME="tex2html663"
  HREF="node21.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous" SRC="prev.png"></A> 
<A NAME="tex2html667"
  HREF="node1.html">
<IMG WIDTH="65" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="contents" SRC="contents.png"></A>  
<BR>
<B> Up:</B> <A NAME="tex2html666"
  HREF="node20.html">Appendices</A>
<B> Previous:</B> <A NAME="tex2html664"
  HREF="node21.html">PTLsim uop Reference</A>
 &nbsp; <B>  <A NAME="tex2html668"
  HREF="node1.html">Contents</A></B> 
<BR>
<BR>
<!--End of Navigation Panel-->
<!--Table of Child-Links-->
<A NAME="CHILD_LINKS"><STRONG>Subsections</STRONG></A>

<UL>
<LI><A NAME="tex2html669"
  HREF="node22.html#SECTION04210000000000000000">General</A>
<LI><A NAME="tex2html670"
  HREF="node22.html#SECTION04220000000000000000">Out of Order Core</A>
<LI><A NAME="tex2html671"
  HREF="node22.html#SECTION04230000000000000000">Cache Subsystem</A>
</UL>
<!--End of Table of Child-Links-->
<HR>

<H1><A NAME="SECTION04200000000000000000"></A><A NAME="sec:PerformanceCounters"></A>
<BR>
Performance Counters
</H1>

<P>
PTLsim maintains hundreds of performance and statistical counters
and data points as it simulates user code. In Section <A HREF="node6.html#sec:StatisticsInfrastructure">4</A>,
the basic mechanisms and data structures through which PTLsim collects
these data were disclosed, and a guide to extending the existing set
of collection points was presented.

<P>
This section is a reference listing of all the current performance
counters present in PTLsim by default. The sections below are arranged
in a hierarchical tree format, just as the data are represented in
PTLsim's data store.

<P>

<H1><A NAME="SECTION04210000000000000000">
General</A>
</H1>

<P>
As described in Section <A HREF="node6.html#sec:StatisticsInfrastructure">4</A>, PTLsim
maintains a hierarchical tree of statistical data. At the root of
the tree are a potentially large number of snapshots, numbered starting
at 0. The final snapshot, taken just before simulation completes,
is labeled as ``final''. Each snapshot branch contains all of
the data structures described in the next few sections. Snapshots
are enabled with the <TT><FONT SIZE="-1">-snapshot</FONT></TT> configuration option
(Section <A HREF="node4.html#sec:ConfigurationOptions">2.3</A>); if they are disabled, only
the ``0'' and ``final'' snapshots are provided.

<P>
In addition to the snapshots, the root of the data tree contains a
``ptlsim'' node with the following miscellaneous information:

<P>
<I><B>ptlsim:</B></I> metadata about the PTLsim build and host
system it is running on

<P>

<UL>
<LI><I><B>executable:</B></I> the full path of the program being simulated
</LI>
<LI><I><B>args:</B></I> arguments to the program being simulated
</LI>
<LI><I><B>hw-ver:</B></I> simulated core hardware version
</LI>
<LI><I><B>ptl-ver:</B></I> microcode version
</LI>
<LI><I><B>build-hostname:</B></I> the machine on which PTLsim was
compiled
</LI>
<LI><I><B>build-timestamp:</B></I> the date on which PTLsim was compiled
(this is set whenever <TT><FONT SIZE="-1">config.o</FONT></TT> is compiled)
</LI>
<LI><I><B>build-compiler-version:</B></I> gcc version used to build
PTLsim
</LI>
<LI><I><B>hostname:</B></I> the host machine PTLsim is running on
</LI>
<LI><I><B>native-mhz:</B></I> the clock speed of the host microprocessor
running PTLsim (this is obtained in accordance with Section <A HREF="node5.html#sec:Timing">3.7</A>)
</LI>
</UL>

<P>

<H1><A NAME="SECTION04220000000000000000">
Out of Order Core</A>
</H1>

<P>
<I><B>summary:</B></I> summarizes the performance of user code
running on the simulator

<P>

<UL>
<LI><I><B>cycles:</B></I> total number of processor cycles simulated
</LI>
<LI><I><B>commits:</B></I> total number of committed uops
</LI>
<LI><I><B>usercommits:</B></I> total number of committed x86 instructions
</LI>
<LI><I><B>issues:</B></I> total number of uops issued. This includes
uops issued more than once by through replay (Section <A HREF="node12.html#sec:Scheduling">9.3</A>).
</LI>
<LI><I><B>ipc:</B></I> Instructions Per Cycle (IPC) statistics

<P>

<UL>
<LI><I><B>commit-in-uops:</B></I> average number of uops committed
per cycle
</LI>
<LI><I><B>issue-in-uops:</B></I> average number of uops issued per
cycle
</LI>
<LI><I><B>commit-in-user-insns:</B></I> average number of x86 instructions
committed per cycle
<BR>
<BR><B><I>NOTE:</I></B> Because one x86 instruction may be broken up
into numerous uops, it is <B><I><U>never</U></I></B> appropriate
to compare IPC figures for committed x86 instructions per clock with
IPC values from a RISC machine. Furthermore, different x86 implementations
use varying numbers of uops per x86 instruction as a matter of encoding,
so even comparing the uop based IPC between x86 implementations or
RISC-like machines is inaccurate. Users are strongly advised to use
relative performance measures instead (e.g. total cycles taken to
complete a given benchmark).
</LI>
</UL>
</LI>
</UL>
<I><B>simulator:</B></I> describes the performance of PTLsim itself.
Useful for tuning the simulator.

<P>

<UL>
<LI><I><B>cycles:</B></I> total time in seconds <I>(not simulated
cycles!)</I> spent in various parts of the simulator. Please refer to
the source code (in <I>ooocore.cpp</I>) for the range of code each
time value corresponds to.
</LI>
<LI><I><B>rate:</B></I> PTLsim simulator performance

<P>

<UL>
<LI><I><B>total-secs:</B></I> total seconds spent in simulation mode
(native mode does not count towards this total)
</LI>
<LI><I><B>cycles-per-sec:</B></I> average number of processor cycles
simulated per second
</LI>
<LI><I><B>issues-per-sec:</B></I> average number of uops issued in
the simulator per second
</LI>
<LI><I><B>commits-per-sec:</B></I> average number of uops committed
in the simulator per second
</LI>
<LI><I><B>user-commits-per-sec:</B></I> average number of x86 instructions
committed in the simulator per second
</LI>
</UL>
</LI>
<LI><I><B>bbcache:</B></I> Decoded basic block cache performance

<P>

<UL>
<LI><I><B>count:</B></I> total basic blocks encountered in the user
code
</LI>
<LI><I><B>inserts:</B></I> insertions into the basic block cache
</LI>
<LI><I><B>removes:</B></I> removals from the basic block cache (e.g.
when a block must be re-translated after unaligned loads and stores
are found, etc.)
</LI>
</UL>
</LI>
</UL>
<I><B>fetch:</B></I> fetch stage statistics

<P>

<UL>
<LI><I><B>width:</B></I> histogram of the fetch width actually used
on each cycle
</LI>
<LI><I><B>stop:</B></I> totals up the reasons why fetching finally
stopped in each cycle

<P>

<UL>
<LI><I><B>icache-miss:</B></I> an instruction cache miss prevented
further fetches
</LI>
<LI><I><B>fetchq-full:</B></I> the uop fetch queue is full
</LI>
<LI><I><B>bogus-rip:</B></I> speculative execution redirected the
fetch unit to an inaccessible (or non-executable) page. The fetch
unit remains stalled in this state until the mis-speculation is resolved.
</LI>
<LI><I><B>branch-taken:</B></I> taken branches to non-sequential addresses
always stop fetching
</LI>
<LI><I><B>full-width:</B></I> the maximum fetch width was utilized
without encountering any of the events above
</LI>
</UL>
</LI>
<LI><I><B>blocks:</B></I> blocks of x86 instructions fetched (typically
the processor can read at most e.g. 16 bytes out of a 64 byte instruction
cache line per cycle)
</LI>
<LI><I><B>uops:</B></I> total number of uops fetched
</LI>
<LI><I><B>user-insns:</B></I> total number of x86 instructions fetched
</LI>
<LI><I><B>opclass:</B></I> histogram of how many uops of various operation
classes passed through the fetch unit. The operation classes are defined
in <TT><FONT SIZE="-1">ptlhwdef.h</FONT></TT> and assigned to various opcodes in <TT><FONT SIZE="-1">ptlhwdef.cpp</FONT></TT>.
</LI>
</UL>
<I><B>frontend:</B></I> frontend pipeline (decode, allocate, rename)
statistics

<P>

<UL>
<LI><I><B>width:</B></I> histogram of the frontend width actually
used on each cycle
</LI>
<LI><I><B>status:</B></I> totals up the reasons why frontend processing
finally stopped in each cycle

<P>

<UL>
<LI><I><B>complete:</B></I> all uops were successfully allocated and
renamed
</LI>
<LI><I><B>fetchq-empty:</B></I> no more uops were available for allocation
</LI>
<LI><I><B>rob-full:</B></I> reorder buffer (ROB) was full
</LI>
<LI><I><B>physregs-full:</B></I> physical register file was full even
though an ROB slot was free
</LI>
<LI><I><B>ldq-full:</B></I> load queue was full (too many loads in
the pipeline) even though physical registers were available
</LI>
<LI><I><B>stq-full:</B></I> store queue was full (too many stores
in the pipeline)
</LI>
</UL>
</LI>
<LI><I><B>renamed:</B></I> summarizes the type of renaming that occurred
for each uop (of the destination, not the operands)

<P>

<UL>
<LI><I><B>none:</B></I> uop did not rename its destination (primarily
for stores and branches)
</LI>
<LI><I><B>reg:</B></I> uop renamed destination architectural register
</LI>
<LI><I><B>flags:</B></I> uop renamed one or more of the ZAPS, CF,
OF flag sets but had no destination architectural register
</LI>
<LI><I><B>reg-and-flags:</B></I> uop renamed one or more of the ZAPS,
CF, OF flag sets as well as a destination architectural register
</LI>
</UL>
</LI>
<LI><I><B>alloc:</B></I> summarizes the type of resource allocation
that occurred for each uop (in addition to its ROB slot):

<P>

<UL>
<LI><I><B>reg:</B></I> uop was allocated a physical register
</LI>
<LI><I><B>ldreg:</B></I> uop was a load and was allocated both a physical
register and a load queue entry
</LI>
<LI><I><B>sfr:</B></I> uop was a store and was allocated a store forwarding
register (SFR), a.k.a. store queue entry
</LI>
<LI><I><B>br:</B></I> uop was a branch and was allocated branch-related
resources (possibly including a destination physical register)
</LI>
</UL>
</LI>
</UL>
<I><B>dispatch:</B></I> dispatch unit statistics

<P>

<UL>
<LI><I><B>source:</B></I> totals up where each operand to each uop
currently resided at the time the uop was dispatched

<P>

<UL>
<LI><I><B>waiting:</B></I> how many operands were waiting (i.e. not
yet ready)
</LI>
<LI><I><B>bypass:</B></I> how many operands would come from the bypass
network if the uop were immediately issued
</LI>
<LI><I><B>physreg:</B></I> how many operands were already written
back to physical registers
</LI>
<LI><I><B>archreg:</B></I> how many operands would be obtained from
architectural registers
</LI>
</UL>
</LI>
<LI><I><B>cluster:</B></I> tracks the number of uops issued to each
cluster (or issue queue) in the processor. This list will vary depending
on the processor configuration. The value <I>none</I> means that no
cluster could accept the uop because all issue queues were full.
</LI>
</UL>
<I><B>issue:</B></I> issue statistics

<P>

<UL>
<LI><I><B>result:</B></I> histogram of the final disposition of issuing
each uop

<P>

<UL>
<LI><I><B>no-fu:</B></I> no functional unit was available within the
uop's assigned cluster even though it was already issued
</LI>
<LI><I><B>replay:</B></I> uop attempted to execute but could not complete,
so it must remain in the issue queue to be replayed. This event generally
occurs when a load or store detects a previously unknown forwarding
dependency on a prior store, when the data to actually store is not
yet available, or when insufficient resources are available to complete
the memory operation. Details are given in Sections <A HREF="node14.html#sec:IssuingLoads">11.1</A>
and <A HREF="node15.html#sec:SplitPhaseStores">12.2</A>.
</LI>
<LI><I><B>misspeculation:</B></I> uop mis-speculated and now all uops
after and including the issued uop must be annulled. This generally
occurs with loads (Section <A HREF="node14.html#sec:IssuingLoads">11.1</A>) and stores (Section
<A HREF="node15.html#sub:AliasCheck">12.2.1</A>) when unaligned accesses or load-store aliasing
occurs. This event is handled in accordance with Section <A HREF="node13.html#sec:SpeculationRecovery">10.2</A>.
</LI>
<LI><I><B>branch-mispredict:</B></I> uop was a branch and mispredicted,
such that all uops after (but not including) the branch uop must be
annulled. See Section <A HREF="node13.html#sec:SpeculationAndRecovery">10</A> for details.
</LI>
<LI><I><B>exception:</B></I> uop caused an exception (though this
may not be a user visible error due to speculative execution)
</LI>
<LI><I><B>complete:</B></I> uop completed successfully. Note that
this does <I>not</I> mean the result is immediately ready; for loads
it simply means the request was issued to the cache.
</LI>
</UL>
</LI>
<LI><I><B>source:</B></I> totals up where each operand to each uop
was read from as it was issued

<P>

<UL>
<LI><I><B>bypass:</B></I> how many operands came directly off the
bypass network
</LI>
<LI><I><B>physreg:</B></I> how many operands were read from physical
registers
</LI>
<LI><I><B>archreg:</B></I> how many operands were read from committed
architectural registers
</LI>
</UL>
</LI>
<LI><I><B>width:</B></I> histogram of the issue width actually used
on each cycle in each cluster. This object is further broken down
by cluster, since various clusters have different issue width and
policies.
</LI>
<LI><I><B>opclass:</B></I> histogram of how many uops of various operation
classes were issued. The operation classes are defined in <TT><FONT SIZE="-1">ptlhwdef.h</FONT></TT>
and assigned to various opcodes in <TT><FONT SIZE="-1">ptlhwdef.cpp</FONT></TT>.
</LI>
</UL>
<I><B>writeback:</B></I> writeback stage statistics

<P>

<UL>
<LI><I><B>total:</B></I> total number of results written back to the
physical register file
</LI>
<LI><I><B>transient:</B></I> transient versus persistent values

<P>

<UL>
<LI><I><B>transient:</B></I> the result technically does not have
to be written back to the physical register file at all, since all
consumers sourced the value off the bypass network and the result
is no longer available since the destination architectural register
pointing to it has since been renamed.
</LI>
<LI><I><B>persistent:</B></I> all values which do not meet the conditions
above and hence must still be written back
</LI>
</UL>
</LI>
<LI><I><B>width:</B></I> histogram of the writeback width actually
used on each cycle in each cluster. This object is further broken
down by cluster, since various clusters have different issue width
and policies.
</LI>
</UL>
<I><B>commit:</B></I> commit unit statistics

<P>

<UL>
<LI><I><B>uops:</B></I> total number of uops committed
</LI>
<LI><I><B>userinsns:</B></I> total number of x86 instructions committed
</LI>
<LI><I><B>result:</B></I> histogram of the final disposition of attempting
to commit each uop

<P>

<UL>
<LI><I><B>none:</B></I> one or more uops comprising the x86 instruction
at the head of the ROB were not yet ready to commit, so commitment
is terminated for that cycle
</LI>
<LI><I><B>ok:</B></I> result was successfully committed
</LI>
<LI><I><B>exception:</B></I> result caused a genuine user visible
exception. Generally this will terminate the simulation.
</LI>
<LI><I><B>skipblock:</B></I> This occurs in extremely rare cases when
the processor must skip over the currently executing instruction (such
as in pathological cases of the <TT><FONT SIZE="-1">rep</FONT></TT> x86 instructions).
</LI>
<LI><I><B>barrier:</B></I> the processor encountered a barrier instruction,
such as a system call, assist or pipeline flush. The frontend has
already been stopped and fetching has been redirected to the code
to handle the barrier; this condition simply commits the barrier instruction
itself.
</LI>
<LI><I><B>stop:</B></I> special case for when the simulation is to
be stopped after committing a certain number of x86 instructions (e.g.
via the <TT><FONT SIZE="-1">-stopinsns</FONT></TT> option in Section <A HREF="node4.html#sec:ConfigurationOptions">2.3</A>).
</LI>
</UL>
</LI>
<LI><I><B>setflags:</B></I> how many uops updated the condition code
flags as they committed

<P>

<UL>
<LI><I><B>yes:</B></I> how many uops updated at least one of the ZAPS,
CF, OF flag sets (the <TT><FONT SIZE="-1">REG_flags</FONT></TT> internal architectural
register)
</LI>
<LI><I><B>no:</B></I> how many uops did not update any flags
</LI>
</UL>
</LI>
<LI><I><B>freereg:</B></I> how many uops were able to free the old
physical register mapped to their architectural destination register
at commit time

<P>

<UL>
<LI><I><B>pending:</B></I> old physical register was still referenced
within the pipeline or by one or more rename table entries
</LI>
<LI><I><B>free:</B></I> old physical register could be immediately
freed
</LI>
</UL>
</LI>
<LI><I><B>physreg-recycled:</B></I> how many physical registers were
recycled (garbage collected) later than normal because of one of the
conditions above
</LI>
<LI><I><B>width:</B></I> histogram of the issue width actually used
on each cycle in each cluster. This object is further broken down
by cluster, since various clusters have different issue width and
policies.
</LI>
<LI><I><B>opclass:</B></I> histogram of how many uops of various operation
classes were issued. The operation classes are defined in <TT><FONT SIZE="-1">ptlhwdef.h</FONT></TT>
and assigned to various opcodes in <TT><FONT SIZE="-1">ptlhwdef.cpp</FONT></TT>.
</LI>
</UL>
<I><B>branchpred:</B></I> branch predictor statistics

<P>

<UL>
<LI><I><B>predictions:</B></I> total number of branch predictions
of any type
</LI>
<LI><I><B>updates:</B></I> total number of branch predictor updates
of any type
</LI>
<LI><I><B>cond:</B></I> conditional branch (<TT><FONT SIZE="-1">br.cc</FONT></TT>
uop) prediction outcomes, broken down into correct predictions and
mispredictions
</LI>
<LI><I><B>indir:</B></I> indirect branch (<TT><FONT SIZE="-1">jmp</FONT></TT> uop)
prediction outcomes, broken down into correct predictions and mispredictions
</LI>
<LI><I><B>return:</B></I> return (<TT><FONT SIZE="-1">jmp</FONT></TT> uop with <TT><FONT SIZE="-1">BRANCH_HINT_RET</FONT></TT>
flag) prediction outcomes, broken down into correct predictions and
mispredictions
</LI>
<LI><I><B>summary:</B></I> summary of all prediction outcomes of the
three types above, broken down into correct predictions and mispredictions
</LI>
<LI><I><B>ras:</B></I> return address stack (RAS) operations

<P>

<UL>
<LI><I><B>push:</B></I> RAS pushes on calls
</LI>
<LI><I><B>push-overflows:</B></I> RAS pushes on calls in which the
RAS overflowed
</LI>
<LI><I><B>pop:</B></I> RAS pops on returns
</LI>
<LI><I><B>pop-underflows:</B></I> RAS pops on returns in which the
RAS was empty
</LI>
<LI><I><B>annuls:</B></I> annulment operations in which speculative
updates to the RAS were rolled back
</LI>
</UL>
</LI>
</UL>

<P>

<H1><A NAME="SECTION04230000000000000000">
Cache Subsystem</A>
</H1>

<P>
<I><B>load:</B></I> load unit statistics

<P>

<UL>
<LI><I><B>result:</B></I> histogram of the final disposition of issuing
each load uop

<P>

<UL>
<LI><I><B>complete:</B></I> cache hit
</LI>
<LI><I><B>miss:</B></I> L1 cache miss, and possibly lower levels as
well (Sections <A HREF="node14.html#sec:CacheMissHandling">11.4</A> and <A HREF="node18.html#sec:InitiatingCacheMiss">15.2</A>)
</LI>
<LI><I><B>exception:</B></I> load generated an exception (typically
a page fault), although the exception may still be speculative (Section
<A HREF="node14.html#sec:IssuingLoads">11.1</A>)
</LI>
<LI><I><B>ordering:</B></I> load was misordered with respect to stores
(Section <A HREF="node15.html#sub:AliasCheck">12.2.1</A>)
</LI>
<LI><I><B>unaligned:</B></I> load was unaligned and will need to be
re-executed as a pair of low and high loads (Sections <A HREF="node7.html#sub:UnalignedLoadsAndStores">5.7</A>
and <A HREF="node14.html#sec:IssuingLoads">11.1</A>)
</LI>
<LI><I><B>replay:</B></I> histogram of events in which a load needed
to be replayed (Section <A HREF="node14.html#sec:IssuingLoads">11.1</A>)

<P>

<UL>
<LI><I><B>sfr-addr-and-data-not-ready:</B></I> load was predicted
to forward data from a prior store (Section <A HREF="node15.html#sub:AliasCheck">12.2.1</A>),
but neither the address nor the data of that store has resolved yet
</LI>
<LI><I><B>sfr-addr-not-ready:</B></I> load was predicted to forward
data from a prior store, but the address of that store has not resolved
yet
</LI>
<LI><I><B>sfr-data-not-ready:</B></I> load address matched a prior
store in the store queue, but the data that store should write has
not resolved yet
</LI>
<LI><I><B>missbuf-full:</B></I> load missed the cache but the miss
buffer and/or LFRQ (Section <A HREF="node18.html#sec:InitiatingCacheMiss">15.2</A>) was full
at the time
</LI>
</UL>
</LI>
</UL>
</LI>
<LI><I><B>hit:</B></I> histogram of the cache hierarchy level each
load finally hit

<P>

<UL>
<LI><I><B>L1:</B></I> L1 cache hit
</LI>
<LI><I><B>L2:</B></I> L1 cache miss, L2 cache hit
</LI>
<LI><I><B>L3:</B></I> L! and L2 cache miss, L3 cache hit
</LI>
<LI><I><B>mem:</B></I> all caches missed; value read from main memory
</LI>
</UL>
</LI>
<LI><I><B>forward:</B></I> histogram of which sources were used to
fill each load

<P>

<UL>
<LI><I><B>cache:</B></I> how many loads obtained all their data from
the cache
</LI>
<LI><I><B>sfr:</B></I> how many loads obtained all their data from
a prior store in the pipeline (i.e. load completely overlapped that
store)
</LI>
<LI><I><B>sfr-and-cache:</B></I> how many loads obtained their data
from a combination of the cache and a prior store
</LI>
</UL>
</LI>
<LI><I><B>dependency:</B></I> histogram of how loads related to previous
stores

<P>

<UL>
<LI><I><B>independent:</B></I> load was independent of any store currently
in the pipeline
</LI>
<LI><I><B>predicted-alias-unresolved:</B></I> load was stalled because
the load store alias predictor (LSAP) predicted that an earlier store
would overlap the load's address address even though that earlier
store's address was unresolved (Section <A HREF="node15.html#sub:AliasCheck">12.2.1</A>)
</LI>
<LI><I><B>stq-address-match:</B></I> load depended on an earlier store
still found in the store queue
</LI>
</UL>
</LI>
<LI><I><B>type:</B></I> histogram of the type of each load uop

<P>

<UL>
<LI><I><B>aligned:</B></I> normal aligned loads
</LI>
<LI><I><B>unaligned:</B></I> special unaligned load uops <TT><FONT SIZE="-1">ld.lo</FONT></TT>
or <TT><FONT SIZE="-1">ld.hi</FONT></TT> (Section <A HREF="node7.html#sub:UnalignedLoadsAndStores">5.7</A>)
</LI>
<LI><I><B>internal:</B></I> loads from PTLsim space by microcode
</LI>
</UL>
</LI>
<LI><I><B>size:</B></I> histogram of the size in bytes of each load
uop
</LI>
<LI><I><B>transfer-L2-to-L1:</B></I> histogram of the types of L2
to L1 line transfers that occurred (Section <A HREF="node18.html#sec:CacheHierarchy">15</A>)

<P>

<UL>
<LI><I><B>full-L2-to-L1:</B></I> all bytes in cache line were transferred
from L2 to L1 cache
</LI>
<LI><I><B>partial-L2-to-L1:</B></I> some bytes in the L1 line were
already valid (because of stores to those bytes), but the remaining
bytes still need to be fetched
</LI>
<LI><I><B>L2-to-L1I:</B></I> all bytes in the L2 line were transferred
into the L1 instruction cache
</LI>
</UL>
</LI>
<LI><I><B>dtlb:</B></I> data cache translation lookaside buffer hit
versus miss rate (Section <A HREF="node18.html#sec:TranslationLookasideBuffers">15.4</A>)
</LI>
</UL>
<I><B>fetch:</B></I> instruction fetch unit statistics (Section
<A HREF="node10.html#sec:FetchStage">7.1</A>)

<P>

<UL>
<LI><I><B>hit:</B></I> histogram of the cache hierarchy level each
fetch finally hit

<P>

<UL>
<LI><I><B>L1:</B></I> L1 cache hit
</LI>
<LI><I><B>L2:</B></I> L1 cache miss, L2 cache hit
</LI>
<LI><I><B>L3:</B></I> L! and L2 cache miss, L3 cache hit
</LI>
<LI><I><B>mem:</B></I> all caches missed; value read from main memory
</LI>
</UL>
</LI>
<LI><I><B>itlb:</B></I> instruction cache translation lookaside buffer
hit versus miss rate (Section <A HREF="node18.html#sec:TranslationLookasideBuffers">15.4</A>)
</LI>
</UL>
<I><B>prefetches:</B></I> prefetch engine statistics

<P>

<UL>
<LI><I><B>in-L1:</B></I> requested data already in L1 cache
</LI>
<LI><I><B>in-L2:</B></I> requested data already in L2 cache (and possibly
also in L1 cache)
</LI>
<LI><I><B>required:</B></I> prefetch was actually required (data was
not cached or was in L3 or lower levels)
</LI>
</UL>
<I><B>missbuf:</B></I> miss buffer performance (Sections <A HREF="node18.html#sec:InitiatingCacheMiss">15.2</A>
and <A HREF="node18.html#sec:FillingCacheMiss">15.3</A>)

<P>

<UL>
<LI><I><B>inserts:</B></I> total number of lines inserted into the
miss buffer
</LI>
<LI><I><B>delivers:</B></I> total number of lines delivered to various
cache hierarchy levels from the miss buffer

<P>

<UL>
<LI><I><B>mem-to-L3:</B></I> deliver line from main memory to the
L3 cache
</LI>
<LI><I><B>L3-to-L2:</B></I> deliver line to the L3 cache to the L2
cache
</LI>
<LI><I><B>L2-to-L1D:</B></I> deliver line from the L2 cache to the
L1 data cache
</LI>
<LI><I><B>L2-to-L1I:</B></I> deliver line from the L2 cache to the
L1 instruction cache
</LI>
</UL>
</LI>
</UL>
<I><B>lfrq:</B></I> load fill request queue (LFRQ) performance
(Sections <A HREF="node18.html#sec:InitiatingCacheMiss">15.2</A> and <A HREF="node18.html#sec:FillingCacheMiss">15.3</A>)

<P>

<UL>
<LI><I><B>inserts:</B></I> total number of loads inserted into the
LFRQ
</LI>
<LI><I><B>wakeups:</B></I> total number of loads awakened from the
LFRQ
</LI>
<LI><I><B>annuls:</B></I> total number of loads annulled in the LFRQ
(after they were annulled in the processor core)
</LI>
<LI><I><B>resets:</B></I> total number of LFRQ resets (all entries
cleared)
</LI>
<LI><I><B>total-latency:</B></I> total latency in cycles of all loads
passing through the LFRQ
</LI>
<LI><I><B>average-miss-latency:</B></I> average load latency, weighted
by cache level hit and latency to that level
</LI>
<LI><I><B>width:</B></I> histogram of how many loads were awakened
per cycle by the LFRQ
</LI>
</UL>
<I><B>store:</B></I> store unit statistics

<P>

<UL>
<LI><I><B>issue:</B></I> histogram of the final disposition of issuing
each store uop

<P>

<UL>
<LI><I><B>complete:</B></I> store completed without problems
</LI>
<LI><I><B>exception:</B></I> store generated an exception (typically
a page fault), although the exception may still be speculative (Section
<A HREF="node15.html#sec:StoreMerging">12.1</A>)
</LI>
<LI><I><B>ordering:</B></I> store detected that a later load in program
order aliased the store but was issued earlier than the store (Section
<A HREF="node15.html#sub:AliasCheck">12.2.1</A>)
</LI>
<LI><I><B>unaligned:</B></I> store was unaligned and will need to
be re-executed as a pair of low and high stores (Sections <A HREF="node7.html#sub:UnalignedLoadsAndStores">5.7</A>)
</LI>
<LI><I><B>replay:</B></I> histogram of events in which a store needed
to be replayed (Sections <A HREF="node15.html#sec:SplitPhaseStores">12.2</A> and <A HREF="node15.html#sec:StoreMerging">12.1</A>)

<P>

<UL>
<LI><I><B>wait-sfraddr-sfrdata:</B></I> neither the address nor the
data of a prior store this store inherits some of its data from was
ready
</LI>
<LI><I><B>wait-sfraddr:</B></I> the data of a prior store was ready
but its address was still unavailable
</LI>
<LI><I><B>wait-sfrdata:</B></I> the address of a prior store was ready
but its data was still unavailable
</LI>
<LI><I><B>wait-storedata-sfraddr-sfrdata:</B></I> the actual data
value to store was not ready (Section <A HREF="node15.html#sec:SplitPhaseStores">12.2</A>),
in addition to having neither the data nor the address of a prior
store (Section <A HREF="node15.html#sec:StoreMerging">12.1</A>)
</LI>
<LI><I><B>wait-storedata-sfraddr:</B></I> the actual data value to
store was not ready (Section <A HREF="node15.html#sec:SplitPhaseStores">12.2</A>), in addition
to not having the address of the prior store (Section <A HREF="node15.html#sec:StoreMerging">12.1</A>)
</LI>
<LI><I><B>wait-storedata-sfrdata:</B></I> the actual data value to
store was not ready (Section <A HREF="node15.html#sec:SplitPhaseStores">12.2</A>), in addition
to not having the data from the prior store (Section <A HREF="node15.html#sec:StoreMerging">12.1</A>)
</LI>
</UL>
</LI>
</UL>
</LI>
<LI><I><B>forward:</B></I> histogram of which sources were used to
construct the merged store buffer:

<P>

<UL>
<LI><I><B>zero:</B></I> no prior store overlapping the current store
was found in the pipeline
</LI>
<LI><I><B>sfr:</B></I> data from a prior store in the pipeline was
merged with the value to be stored to form the final store buffer
</LI>
</UL>
</LI>
<LI><I><B>type:</B></I> histogram of the type of each store uop

<P>

<UL>
<LI><I><B>aligned:</B></I> normal aligned store
</LI>
<LI><I><B>unaligned:</B></I> special unaligned store uops <TT><FONT SIZE="-1">st.lo</FONT></TT>
or <TT><FONT SIZE="-1">st.hi</FONT></TT> (Section <A HREF="node7.html#sub:UnalignedLoadsAndStores">5.7</A>)
</LI>
<LI><I><B>internal:</B></I> stores to PTLsim space by microcode
</LI>
</UL>
</LI>
<LI><I><B>size:</B></I> histogram of the size in bytes of each store
uop
</LI>
<LI><I><B>commit:</B></I> histogram of how stores are committed

<P>

<UL>
<LI><I><B>direct:</B></I> store committed directly to the data cache
in the commit stage (Section <A HREF="node17.html#sec:CommitStage">14</A>)
</LI>
</UL>
</LI>
</UL>

<DIV ALIGN="CENTER">
<B><I>The End</I></B>
</DIV><HR>
<!--Navigation Panel-->
<IMG WIDTH="81" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next_inactive" SRC="nx_grp_g.png"> 
<A NAME="tex2html665"
  HREF="node20.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up" SRC="up.png"></A> 
<A NAME="tex2html663"
  HREF="node21.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous" SRC="prev.png"></A> 
<A NAME="tex2html667"
  HREF="node1.html">
<IMG WIDTH="65" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="contents" SRC="contents.png"></A>  
<BR>
<B> Up:</B> <A NAME="tex2html666"
  HREF="node20.html">Appendices</A>
<B> Previous:</B> <A NAME="tex2html664"
  HREF="node21.html">PTLsim uop Reference</A>
 &nbsp; <B>  <A NAME="tex2html668"
  HREF="node1.html">Contents</A></B> 
<!--End of Navigation Panel-->
<ADDRESS>
Matt T Yourst
2005-12-02
</ADDRESS>
</BODY>
</HTML>
